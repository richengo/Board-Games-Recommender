{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Board Games\n",
    "__________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import sqlite3\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "# import math\n",
    "# import random\n",
    "# import sklearn\n",
    "# import scipy\n",
    "import cv2\n",
    "\n",
    "# Recommender\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "from tensorflow.keras.layers import Embedding, Dense, Layer\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data  \n",
    "\n",
    "Import the cleaned dataframe, reference dictionaries, and user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dataframe\n",
    "infile = open('../datasets/boardgames/clean_bgg_GameItem.pkl', 'rb')\n",
    "df = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7929, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dictionaries\n",
    "infile = open('../datasets/boardgames/ref_dictionaries.pkl', 'rb')\n",
    "ref_dicts = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_user_name</th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>bgg_user_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>user_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fu_koios</td>\n",
       "      <td>223033</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-=yod@=-</td>\n",
       "      <td>7</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-=yod@=-</td>\n",
       "      <td>42</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-=yod@=-</td>\n",
       "      <td>217</td>\n",
       "      <td>6.75</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-=yod@=-</td>\n",
       "      <td>432</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bgg_user_name  bgg_id  bgg_user_rating  year  month  user_count\n",
       "0     fu_koios   223033             9.00  2017     10           1\n",
       "1      -=yod@=-       7             7.50  2015      3         173\n",
       "2      -=yod@=-      42             6.50  2016     10         173\n",
       "3      -=yod@=-     217             6.75  2016     10         173\n",
       "4      -=yod@=-     432             7.50  2017      5         173"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract ratings from sqlite database\n",
    "conn = sqlite3.connect(\"../datasets/boardgames/bgg_5yrs_RatingItem.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "user_df = pd.read_sql_query(\"\"\"\n",
    "SELECT *,\n",
    "    COUNT(bgg_user_name) OVER\n",
    "         (PARTITION BY bgg_user_name) AS user_count\n",
    "FROM bgg_ratings\n",
    "\n",
    "\"\"\", conn)\n",
    "\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12278237, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "A common problem in recommender systems is known as ***user cold-start***, where it is difficult to recommend items for users with very few number of consumed items (in this case rated board games), due to lack of information to model their preferences. As such, we choose to only keep the users with at least 30 rated board games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10667845, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering dataframe to contain users with at least 30 rates\n",
    "user_df = user_df[user_df['user_count']>=30]\n",
    "user_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to extract the user ratings for the board games that we are left with after extensive EDA and cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9182849, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering dataframe to user ratings of the board games we are concerned with\n",
    "user_df = user_df[user_df['bgg_id'].isin(df['bgg_id'])]\n",
    "user_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9.182849e+06\n",
       "mean     2.552930e+02\n",
       "std      3.462861e+02\n",
       "min      3.000000e+01\n",
       "25%      7.900000e+01\n",
       "50%      1.560000e+02\n",
       "75%      3.160000e+02\n",
       "max      6.717000e+03\n",
       "Name: user_count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df['user_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df as .pkl\n",
    "outfile = open('../datasets/boardgames/bgg_users_2015.pkl', 'wb')\n",
    "pickle.dump(user_df, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Board Game Mapper\n",
    "\n",
    "We require a mapper for board game id to the board game name since our predictions would be done on the board game ids. This mapper will be user at the end after an actual prediction has been made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapper (bgg_id -> name)\n",
    "bg_mapper = {}\n",
    "for i, name in zip(df['bgg_id'], df['name']):\n",
    "    bg_mapper[str(i)] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique id  \n",
    "\n",
    "We require to map the board game ids to embedding vectors in the models later. Hence, we need lists of the unique board game ids and unique user ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique users and unique board game ids\n",
    "# Need to keep it as numpy.ndarray\n",
    "unique_user = user_df['bgg_user_name'].unique()\n",
    "unique_bgg_id = df['bgg_id'].unique().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '9', '10', '11', '12', '13', '14', '16', '17', '25'],\n",
       "      dtype='<U21')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_bgg_id[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Model\n",
    "\n",
    "This is a two-tower retrieval model, we will build each tower separately and then combine them in the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and test sets\n",
    "\n",
    "We want to split the user dataframe into train and test sets, by time. The data up to time $T$ would be used to predict user rating after $T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort user dataframe by date\n",
    "user_df = user_df.sort_values(by=['year', 'month']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert train and test into Tensor Datasets\n",
    "user_dict = {'bgg_id': user_df['bgg_id'].astype(str),\n",
    "            'bgg_user_name': user_df['bgg_user_name']}\n",
    "user_data = tf.data.Dataset.from_tensor_slices(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "num_entries = tf.get_static_value(user_data.__len__())\n",
    "train_split = int(np.ceil(0.8*num_entries))\n",
    "test_split = int(np.floor(0.2*num_entries))\n",
    "\n",
    "user_train = user_data.take(train_split)\n",
    "user_test = user_data.skip(train_split).take(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "## THIS WAS LAST SUCCESSFUL\n",
    "# Split dataset with shuffle False\n",
    "# We only need the user name and bgg_id\n",
    "# user_train, user_test = train_test_split(user_df[['bgg_id', 'bgg_user_name']], shuffle=False, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and test into Tensor Datasets\n",
    "# user_train = user_train.to_dict('records')\n",
    "# user_train = tf.data.Dataset.from_tensor_slices(user_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_test = user_test.to_dict('records')\n",
    "# user_test = tf.data.Dataset.from_tensor_slices(user_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## THIS WAS LAST SUCCESSFUL\n",
    "# Convert train and test into Tensor Datasets\n",
    "# user_train['bgg_id'] = user_train['bgg_id'].astype(str)\n",
    "# user_test['bgg_id'] = user_test['bgg_id'].astype(str)\n",
    "# user_train = tf.data.Dataset.from_tensor_slices(user_train)\n",
    "# user_test = tf.data.Dataset.from_tensor_slices(user_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality of the query\n",
    "embedding_dimension = 32\n",
    "\n",
    "# Define the model\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=unique_user, mask_token=None),\n",
    "    # Additional embedding to account for unknwon tokens\n",
    "    tf.keras.layers.Embedding(len(unique_user) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidate tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Embedding(1000, 64))\n",
    "# # The model will take as input an integer matrix of size (batch,\n",
    "# # input_length), and the largest integer (i.e. word index) in the input\n",
    "# # should be no larger than 999 (vocabulary size).\n",
    "# # Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
    "# # dimension.\n",
    "# input_array = np.random.randint(1000, size=(32, 10))\n",
    "# model.compile('rmsprop', 'mse')\n",
    "# output_array = model.predict(input_array)\n",
    "# print(output_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model for board game names\n",
    "bg_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "        vocabulary=unique_bgg_id, mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(unique_bgg_id) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "In the training data, there are positive (bgg_id, bgg_user_name) pairs. To gauge on how good the model is, we need to compare the affinity score that the model calculates for a particular pair to the scores of all the other possible candidates. In other words, the higher the score for the positive pair as compared to other candidates, the more accurate the model is.\n",
    "\n",
    "We use `FactorizedTopK` metric which requires the dataset of candidates that are used as implicit negatives for evaluation. We are implicitly assuming that if a user did not rate a board game, he/she do not like that board game as much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['bgg_id'].values.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf.data.Dataset.from_tensor_slices(df['bgg_id'].values.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor Dataset object\n",
    "bgg_ids = tf.data.Dataset.from_tensor_slices(df['bgg_id'].values.astype(str))\n",
    "\n",
    "# The metrics\n",
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=bgg_ids.batch(128).map(bg_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss\n",
    "\n",
    "We use the `Retrieval` task object to bundle together the loss function and metric computation. This becomes a Keras layer that takes the embeddings from the two towers as arguments, and returning the computed loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the task\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full model\n",
    "\n",
    "We want to combine all of the above together into a model. We use `tfrs.Model` as the base model which take care of creating the appropriate training loop to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=1836569>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_test.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bgg_id': array([b'146021', b'214880', b'39856', ..., b'221965', b'244654',\n",
      "       b'246855'], dtype=object), 'bgg_user_name': array([b'nickster1970', b'nicktaruffi', b'nickwatt', ..., b'olli_gold',\n",
      "       b'olli_gold', b'olli_gold'], dtype=object)}\n",
      "{'bgg_id': array([b'247694', b'266444', b'760', ..., b'98778', b'100901', b'102652'],\n",
      "      dtype=object), 'bgg_user_name': array([b'olli_gold', b'olli_gold', b'olliesons', ..., b'pchomp',\n",
      "       b'pchomp', b'pchomp'], dtype=object)}\n",
      "{'bgg_id': array([b'119890', b'129622', b'140620', ..., b'113294', b'182874',\n",
      "       b'201808'], dtype=object), 'bgg_user_name': array([b'pchomp', b'pchomp', b'pchomp', ..., b'pouringraine',\n",
      "       b'pouringraine', b'pouringraine'], dtype=object)}\n",
      "{'bgg_id': array([b'269725', b'224517', b'264220', ..., b'284294', b'184267',\n",
      "       b'50381'], dtype=object), 'bgg_user_name': array([b'pouringraine', b'pouvla', b'pouvla', ..., b'raquelnilla',\n",
      "       b'rarekarrde', b'raremind'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "# Check the format of train and test datasets\n",
    "count = 0\n",
    "\n",
    "for element in user_test.batch(4096).as_numpy_iterator():\n",
    "    if count <=3:\n",
    "        print(element)\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model\n",
    "class BGRetrievalModel(tfrs.Model):\n",
    "    \n",
    "    def __init__(self, user_model, bg_model):\n",
    "        super().__init__()\n",
    "        self.bg_model: tf.keras.Model = bg_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "    \n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        # Picking out the user features and passing them into the user model\n",
    "        # Format of each entry is ['bgg_id', 'bgg_user_name']\n",
    "        user_embeddings = self.user_model(features['bgg_user_name'])\n",
    "        \n",
    "        # Picking out the board games features, passing into bg model\n",
    "        positive_bg_embeddings = self.bg_model(features['bgg_id'])\n",
    "        \n",
    "        # Task computes the loss and the metrics\n",
    "        return self.task(user_embeddings, positive_bg_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and Evaluation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and compile the model\n",
    "retrieval_model = BGRetrievalModel(user_model, bg_model)\n",
    "retrieval_model.compile(optimizer=Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and cache the datasets, did not shuffle to keep time order\n",
    "cached_user_train = user_train.batch(8192).cache()\n",
    "cached_user_test = user_test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CacheDataset shapes: {bgg_id: (None,), bgg_user_name: (None,)}, types: {bgg_id: tf.string, bgg_user_name: tf.string}>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_user_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n",
      " 13/897 [..............................] - ETA: 10:00 - factorized_top_k/top_1_categorical_accuracy: 0.0115 - factorized_top_k/top_5_categorical_accuracy: 0.0433 - factorized_top_k/top_10_categorical_accuracy: 0.0701 - factorized_top_k/top_50_categorical_accuracy: 0.1840 - factorized_top_k/top_100_categorical_accuracy: 0.2594 - loss: 71218.0691 - regularization_loss: 0.0000e+00 - total_loss: 71218.0691"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-0c6a5c1ceec2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mretrieval_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcached_user_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "retrieval_model.fit(cached_user_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 21s 46ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2383 - factorized_top_k/top_5_categorical_accuracy: 0.2450 - factorized_top_k/top_10_categorical_accuracy: 0.2517 - factorized_top_k/top_50_categorical_accuracy: 0.2739 - factorized_top_k/top_100_categorical_accuracy: 0.2884 - loss: 0.6933 - regularization_loss: 0.0000e+00 - total_loss: 0.69331s - factorized_top_k/top_1_categorical_accuracy: 0.2422 - factorized_top_k/top_5_categorical_accuracy: 0.2494 - factorized_top_k/top_10_categorical_accuracy: 0.2554 - factorized_top_k/top_50_categorical_accuracy: 0.2795 - factorized_top_k/top_100_categorical_accuracy: 0.2940 - loss: 0.6916 - regularization_l\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.23830735683441162,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.24498885869979858,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.25167039036750793,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.27394208312034607,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.288418710231781,\n",
       " 'loss': 0.8462238907814026,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 0.8462238907814026}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "retrieval_model.evaluate(cached_user_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values tell us whether the true positive is in the top-k retrieved items from the entire candidate set. For example, a top-50 categorical accuracy metric of 0.3 means that 30% of the top 50 retrieved items are true positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the metrics, there is a considerable difference between the train and test accuracies, suggesting that the model has been overfitted. It is common since the model has many parameters. A low top-k accuracy would also suggest that the model is recommending board games to users who already rated those board games.\n",
    "\n",
    "(Maybe can try regularization to generalize better to unseen data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>game_type</th>\n",
       "      <th>designer</th>\n",
       "      <th>artist</th>\n",
       "      <th>publisher</th>\n",
       "      <th>min_players</th>\n",
       "      <th>max_players</th>\n",
       "      <th>min_age</th>\n",
       "      <th>min_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>category</th>\n",
       "      <th>mechanic</th>\n",
       "      <th>rank</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>stddev_rating</th>\n",
       "      <th>bayes_rating</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Samurai</td>\n",
       "      <td>1998</td>\n",
       "      <td>5497</td>\n",
       "      <td>2</td>\n",
       "      <td>11883</td>\n",
       "      <td>17,133,267,29,7340,7335,41,2973,4617,1391,8291...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1009,1035</td>\n",
       "      <td>2080,2040,2026,2846,2004,2002</td>\n",
       "      <td>207.0</td>\n",
       "      <td>14648.0</td>\n",
       "      <td>7.45046</td>\n",
       "      <td>1.18569</td>\n",
       "      <td>7.24774</td>\n",
       "      <td>2.4885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>El Caballero</td>\n",
       "      <td>1998</td>\n",
       "      <td>5497</td>\n",
       "      <td>7,8</td>\n",
       "      <td>74</td>\n",
       "      <td>267,133,3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1020</td>\n",
       "      <td>2080,2002</td>\n",
       "      <td>2679.0</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>6.46354</td>\n",
       "      <td>1.43462</td>\n",
       "      <td>5.94897</td>\n",
       "      <td>3.1824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bgg_id          name  year game_type designer artist  \\\n",
       "0       3       Samurai  1998      5497        2  11883   \n",
       "1       9  El Caballero  1998      5497      7,8     74   \n",
       "\n",
       "                                           publisher min_players max_players  \\\n",
       "0  17,133,267,29,7340,7335,41,2973,4617,1391,8291...           2           4   \n",
       "1                                          267,133,3           2           4   \n",
       "\n",
       "   min_age  min_time  max_time   category                       mechanic  \\\n",
       "0     10.0      30.0      60.0  1009,1035  2080,2040,2026,2846,2004,2002   \n",
       "1     13.0      90.0      90.0       1020                      2080,2002   \n",
       "\n",
       "     rank  num_votes  avg_rating  stddev_rating  bayes_rating  complexity  \n",
       "0   207.0    14648.0     7.45046        1.18569       7.24774      2.4885  \n",
       "1  2679.0     1374.0     6.46354        1.43462       5.94897      3.1824  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Board game dataset needs to be Tensorflow object\n",
    "bgg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x20492623c10>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model that takes in raw query features\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(retrieval_model.user_model)\n",
    "\n",
    "# Recommends a board game out of the entire boardgame dataset\n",
    "index.index(bgg_ids.batch(128).map(retrieval_model.bg_model), bgg_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for -johnny-: [b'224031' b'28185' b'85036']\n"
     ]
    }
   ],
   "source": [
    "# Get recommendation\n",
    "_, board_games = index(tf.constant(['-johnny-']))\n",
    "print(f'Recommendations for -johnny-: {board_games[0, :3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to successfully recommend top 3 games (number of games arbituarily decided) to a user with the username '-johnny-' based on the trained embeddings for both the query tower and candidate tower. However, we are recommending the board game id right now, and we want to map that to the board game name for it to be more meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for -johnny-: ['Cartagena', \"The Kaiser's Pirates\", '20th Century']\n"
     ]
    }
   ],
   "source": [
    "# Map the predicted bgg_id to the board game name\n",
    "named_games = []\n",
    "for bgg_id in board_games[0, :3]:\n",
    "    named_games.append(bg_mapper[bgg_id.numpy().decode(\"utf-8\")])\n",
    "\n",
    "print(f'Recommendations for -johnny-: {named_games}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_user_name</th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>bgg_user_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>user_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>59946</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>166384</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73899</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>150376</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132254</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>150658</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191533</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>478</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191534</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>103885</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354534</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>18833</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354535</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>54307</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056490</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>94</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056491</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>26566</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056492</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>41114</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056493</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>161936</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016197</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>148261</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753589</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>223855</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125592</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>157096</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262569</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>34084</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262570</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>225818</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3432492</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>96848</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553050</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>173442</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912965</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>8935</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912966</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>10093</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912967</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>15987</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912968</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>92415</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912969</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>103886</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912970</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>129622</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912971</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>221107</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017364</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>55690</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128299</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>24509</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660493</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>119788</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001212</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>903</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001213</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>118063</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143191</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>203416</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143192</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>203420</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143193</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>264198</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553903</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>37111</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553904</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>173341</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553905</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>203417</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bgg_user_name  bgg_id  bgg_user_rating  year  month  user_count\n",
       "1            -johnny-   59946              6.0  2015      1          45\n",
       "2            -johnny-  166384              7.0  2015      1          45\n",
       "73899        -johnny-  150376              6.0  2015      2          45\n",
       "132254       -johnny-  150658              6.0  2015      3          45\n",
       "191533       -johnny-     478              6.0  2015      4          45\n",
       "191534       -johnny-  103885              5.0  2015      4          45\n",
       "354534       -johnny-   18833              9.0  2015      7          45\n",
       "354535       -johnny-   54307              8.0  2015      7          45\n",
       "1056490      -johnny-      94              8.0  2016      4          45\n",
       "1056491      -johnny-   26566              4.0  2016      4          45\n",
       "1056492      -johnny-   41114              8.0  2016      4          45\n",
       "1056493      -johnny-  161936              9.0  2016      4          45\n",
       "2016197      -johnny-  148261              4.0  2017      2          45\n",
       "2753589      -johnny-  223855              4.0  2017      9          45\n",
       "3125592      -johnny-  157096              4.0  2017     12          45\n",
       "3262569      -johnny-   34084              8.0  2018      1          45\n",
       "3262570      -johnny-  225818              3.0  2018      1          45\n",
       "3432492      -johnny-   96848              5.0  2018      2          45\n",
       "3553050      -johnny-  173442              6.0  2018      3          45\n",
       "3912965      -johnny-    8935              9.0  2018      6          45\n",
       "3912966      -johnny-   10093              9.0  2018      6          45\n",
       "3912967      -johnny-   15987              8.0  2018      6          45\n",
       "3912968      -johnny-   92415              9.0  2018      6          45\n",
       "3912969      -johnny-  103886              7.0  2018      6          45\n",
       "3912970      -johnny-  129622              7.0  2018      6          45\n",
       "3912971      -johnny-  221107              9.0  2018      6          45\n",
       "4017364      -johnny-   55690              4.0  2018      7          45\n",
       "4128299      -johnny-   24509              7.0  2018      8          45\n",
       "4660493      -johnny-  119788              5.0  2018     12          45\n",
       "5001212      -johnny-     903              8.0  2019      2          45\n",
       "5001213      -johnny-  118063              6.0  2019      2          45\n",
       "5143191      -johnny-  203416              6.0  2019      3          45\n",
       "5143192      -johnny-  203420              6.0  2019      3          45\n",
       "5143193      -johnny-  264198              5.0  2019      3          45\n",
       "6553903      -johnny-   37111              9.0  2019     12          45\n",
       "6553904      -johnny-  173341              6.0  2019     12          45\n",
       "6553905      -johnny-  203417              6.0  2019     12          45"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if our model is re-recommending the user a game he or she has already played\n",
    "user_df[user_df['bgg_user_name']=='-johnny-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the board games which the user '-johnny-' has rated, we see that the top 3 recommended games are not within them. This is still a good sign, but it may be just so happened that these 45 entries have no false positives. \n",
    "\n",
    "The retrieval model is useful for getting quick recommendations, but it is just based on the board game ids and user ids. This model is usually built to be more computationally efficient to filter out all candidates that the user is not interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Model\n",
    "\n",
    "The ranking model is built to be used in tandem with the retrieval model, taking the outputs from the retrieval model and finetuning them to select the best possible recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and test sets\n",
    "\n",
    "The train and test data will now include the user ratings to give a sense of ranking to the recommended board games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_train, rating_test = train_test_split(user_df[['bgg_id', 'bgg_user_name', 'bgg_user_rating']], shuffle=False, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1836570, 2), dtype=string, numpy=\n",
       "array([[b'113294', b'nickster1970'],\n",
       "       [b'146021', b'nickster1970'],\n",
       "       [b'214880', b'nicktaruffi'],\n",
       "       ...,\n",
       "       [b'233867', b'zzzzzane'],\n",
       "       [b'242302', b'zzzzzane'],\n",
       "       [b'269210', b'zzzzzane']], dtype=object)>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(rating_test[['bgg_id', 'bgg_user_name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1836570,), dtype=float64, numpy=array([7. , 8. , 8. , ..., 8. , 7.5, 8. ])>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(rating_test['bgg_user_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and test into Tensor Datasets\n",
    "tensor_user_train = tf.data.Dataset.from_tensor_slices(rating_train[['bgg_id', 'bgg_user_name']].astype(str))\n",
    "tensor_user_test = tf.data.Dataset.from_tensor_slices(rating_test[['bgg_id', 'bgg_user_name']].astype(str))\n",
    "tensor_rating_train = tf.data.Dataset.from_tensor_slices(rating_train['bgg_user_rating'].astype('float32'))\n",
    "tensor_rating_test = tf.data.Dataset.from_tensor_slices(rating_test['bgg_user_rating'].astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "rating_train = tf.data.Dataset.zip((tensor_user_train, tensor_rating_train))\n",
    "rating_test = tf.data.Dataset.zip((tensor_user_test, tensor_rating_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ZipDataset shapes: ((2,), ()), types: (tf.string, tf.float32)>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert train and test into Tensor Datasets\n",
    "# rating_train['bgg_id'] = rating_train['bgg_id'].astype(str)\n",
    "# rating_test['bgg_id'] = rating_test['bgg_id'].astype(str)\n",
    "# # rating_train['bgg_user_rating'] = rating_train['bgg_user_rating'].astype('float32')\n",
    "# # rating_test['bgg_user_rating'] = rating_test['bgg_user_rating'].astype('float32')\n",
    "\n",
    "\n",
    "# rating_train = tf.data.Dataset.from_tensor_slices(rating_train[['bgg_id', 'bgg_user_name']], rating_train['bgg_user_rating'])\n",
    "# rating_test = tf.data.Dataset.from_tensor_slices(rating_test[['bgg_id', 'bgg_user_name']], rating_test['bgg_user_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking layers\n",
    "\n",
    "The ranking model is composed of multiple layers for ranking tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking tasks\n",
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # User embeddings\n",
    "        self.user_embeddings = Sequential([\n",
    "            StringLookup(vocabulary=unique_user, mask_token=None),\n",
    "            Embedding(len(unique_user) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Board game embeddings\n",
    "        self.bg_embeddings = Sequential([\n",
    "            StringLookup(vocabulary=unique_bgg_id, mask_token=None),\n",
    "            Embedding(len(unique_bgg_id) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Predictions\n",
    "        self.ratings = Sequential([\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "          # Rating predictions in the final layer.\n",
    "            Dense(1)\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        bgg_user_name, bgg_id = inputs\n",
    "        user_embedding = self.user_embeddings(bgg_user_name)\n",
    "        bg_embedding = self.bg_embeddings(bgg_id)\n",
    "        return self.ratings(tf.concat([user_embedding, bg_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['-johnny-']\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['20545']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[-0.02250871]], dtype=float32)>"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This model takes user names and bgg ids, and outputs a predicted rating\n",
    "RankingModel()((['-johnny-'],['20545']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.01110805]], dtype=float32)>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This model takes user names and bgg ids, and outputs a predicted rating\n",
    "# RankingModel()(tf.convert_to_tensor((['-johnny-'],['20545'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and metrics\n",
    "\n",
    "This time, we use the `Ranking` task object to put together the loss function and metric computation. The metrics used is `RootMeanSquaredError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss + metrics task\n",
    "task = tfrs.tasks.Ranking(\n",
    "    loss = MeanSquaredError(),\n",
    "    metrics = [RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full model\n",
    "\n",
    "We want to combine all of the above together into a model. We use `tfrs.Model` as the base model which take care of creating the appropriate training loop to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 2), (None,)), types: (tf.string, tf.float32)>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_test.batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([b'113294', b'nickster1970'], dtype=object), 7.0)\n",
      "(array([b'146021', b'nickster1970'], dtype=object), 8.0)\n",
      "(array([b'214880', b'nicktaruffi'], dtype=object), 8.0)\n",
      "(array([b'39856', b'nickwatt'], dtype=object), 7.0)\n",
      "(array([b'92828', b'nickwatt'], dtype=object), 7.0)\n",
      "(array([b'218603', b'nickwatt'], dtype=object), 8.0)\n",
      "(array([b'246784', b'nickwatt'], dtype=object), 8.5)\n",
      "(array([b'247160', b'nickwatt'], dtype=object), 7.0)\n",
      "(array([b'24181', b'nicnied'], dtype=object), 9.5)\n",
      "(array([b'35497', b'nicnied'], dtype=object), 4.0)\n",
      "(array([b'132372', b'nicnied'], dtype=object), 7.0)\n"
     ]
    }
   ],
   "source": [
    "# Check the format of train and test datasets\n",
    "count = 0\n",
    "for element in rating_test.as_numpy_iterator():\n",
    "    if count <=10:\n",
    "        print(element)\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model\n",
    "class BGRankingModel(tfrs.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel()\n",
    "        # The loss + metrics task\n",
    "        self.task: Layer = tfrs.tasks.Ranking(\n",
    "            loss = MeanSquaredError(),\n",
    "            metrics = [RootMeanSquaredError()]\n",
    "        )\n",
    "    \n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "        rating_predictions = self.ranking_model(\n",
    "            ([features[0][1]], [features[0][0]]))\n",
    "        \n",
    "        # Task computes the loss and the metrics\n",
    "        return self.task(labels=features[1], predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and compile the model\n",
    "ranking_model = BGRankingModel()\n",
    "ranking_model.compile(optimizer=Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and cache the datasets, did not shuffle to keep time order\n",
    "cached_rating_train = rating_train.batch(8192).cache()\n",
    "cached_rating_test = rating_test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, None, 2), (None, None)), types: (tf.string, tf.float32)>"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_rating_train.batch(8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([b'113294', b'nickster1970'], dtype=object), 7.0)\n",
      "(array([b'146021', b'nickster1970'], dtype=object), 8.0)\n",
      "(array([b'214880', b'nicktaruffi'], dtype=object), 8.0)\n"
     ]
    }
   ],
   "source": [
    "# Check the format of train and test datasets\n",
    "count = 0\n",
    "for element in rating_test.as_numpy_iterator():\n",
    "    if count <=2:\n",
    "        print(element)\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'nickster1970'\n",
      "b'pchomp'\n",
      "b'raremind'\n"
     ]
    }
   ],
   "source": [
    "# Check the format of train and test datasets\n",
    "count = 0\n",
    "for element in rating_test.batch(8192).as_numpy_iterator():\n",
    "    if count <=2:\n",
    "        print(element[0][0][1])\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'strided_slice:0' shape=(2,) dtype=string>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'strided_slice_1:0' shape=(2,) dtype=string>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'strided_slice:0' shape=(2,) dtype=string>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'strided_slice_1:0' shape=(2,) dtype=string>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "897/897 [==============================] - 11s 12ms/step - root_mean_squared_error: 1.5448 - loss: 2.3857 - regularization_loss: 0.0000e+00 - total_loss: 2.3857\n",
      "Epoch 2/3\n",
      "897/897 [==============================] - 7s 8ms/step - root_mean_squared_error: 1.4586 - loss: 2.1272 - regularization_loss: 0.0000e+00 - total_loss: 2.1272\n",
      "Epoch 3/3\n",
      "897/897 [==============================] - 7s 8ms/step - root_mean_squared_error: 1.4577 - loss: 2.1245 - regularization_loss: 0.0000e+00 - total_loss: 2.1245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2048b63f700>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "ranking_model.fit(cached_rating_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'strided_slice:0' shape=(2,) dtype=string>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: [<tf.Tensor 'strided_slice_1:0' shape=(2,) dtype=string>]\n",
      "Consider rewriting this model with the Functional API.\n",
      "449/449 [==============================] - 3s 7ms/step - root_mean_squared_error: 1.4409 - loss: 2.0750 - regularization_loss: 0.0000e+00 - total_loss: 2.0750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 1.4409151077270508,\n",
       " 'loss': 1.7327253818511963,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 1.7327253818511963}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "ranking_model.evaluate(cached_rating_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the rmse and loss are both lower than the train data, there may be some underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_user_name</th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>bgg_user_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>user_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-=yod@=-</td>\n",
       "      <td>160495</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>59946</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>166384</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-mide-</td>\n",
       "      <td>20545</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-mide-</td>\n",
       "      <td>145639</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bgg_user_name  bgg_id  bgg_user_rating  year  month  user_count\n",
       "0      -=yod@=-  160495              7.5  2015      1         173\n",
       "1      -johnny-   59946              6.0  2015      1          45\n",
       "2      -johnny-  166384              7.0  2015      1          45\n",
       "3        -mide-   20545              6.0  2015      1         130\n",
       "4        -mide-  145639              7.0  2015      1         130"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(features, msg1, msg2):\n",
    "    print(features)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictdict = {'col1': [1,2,3,4],\n",
    "           'col2': ['4','3','2','1']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'col1': <tf.Tensor: shape=(), dtype=int32, numpy=1>, 'col2': <tf.Tensor: shape=(), dtype=string, numpy=b'4'>}\n",
      "{'col1': <tf.Tensor: shape=(), dtype=int32, numpy=2>, 'col2': <tf.Tensor: shape=(), dtype=string, numpy=b'3'>}\n",
      "{'col1': <tf.Tensor: shape=(), dtype=int32, numpy=3>, 'col2': <tf.Tensor: shape=(), dtype=string, numpy=b'2'>}\n",
      "{'col1': <tf.Tensor: shape=(), dtype=int32, numpy=4>, 'col2': <tf.Tensor: shape=(), dtype=string, numpy=b'1'>}\n"
     ]
    }
   ],
   "source": [
    "for x in tf.data.Dataset.from_tensor_slices(dictdict):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to explore more models which are able to utilize the rich features which our datasets possess, also to give better recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based Recommender\n",
    "\n",
    "In content-based filtering, the features of the dataframe are broken down into \"feature baskets\". These are the characteristics that represent a board game. The main idea is that if the user likes certain categories, mechanics, or types of a certain board game, then it is likely the user likes another board game that has similar characteristics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tuple(df['bgg_id'])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
