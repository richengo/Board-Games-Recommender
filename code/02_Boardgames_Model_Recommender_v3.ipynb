{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Board Games\n",
    "__________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import sqlite3\n",
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "# import math\n",
    "# import random\n",
    "# import sklearn\n",
    "# import scipy\n",
    "import cv2\n",
    "\n",
    "# Recommender\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup, TextVectorization, Normalization, Discretization, Hashing\n",
    "from tensorflow.keras.layers import Embedding, Dense, Layer, GlobalAveragePooling1D, Flatten\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data  \n",
    "\n",
    "Import the cleaned dataframe, reference dictionaries, and user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dataframe\n",
    "infile = open('../datasets/boardgames/clean_bgg_GameItem.pkl', 'rb')\n",
    "df = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7929, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open dictionaries\n",
    "infile = open('../datasets/boardgames/ref_dictionaries.pkl', 'rb')\n",
    "ref_dicts = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_user_name</th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>bgg_user_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>user_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fu_koios</td>\n",
       "      <td>223033</td>\n",
       "      <td>9.00</td>\n",
       "      <td>2017</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-=yod@=-</td>\n",
       "      <td>7</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-=yod@=-</td>\n",
       "      <td>42</td>\n",
       "      <td>6.50</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-=yod@=-</td>\n",
       "      <td>217</td>\n",
       "      <td>6.75</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-=yod@=-</td>\n",
       "      <td>432</td>\n",
       "      <td>7.50</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bgg_user_name  bgg_id  bgg_user_rating  year  month  user_count\n",
       "0     fu_koios   223033             9.00  2017     10           1\n",
       "1      -=yod@=-       7             7.50  2015      3         173\n",
       "2      -=yod@=-      42             6.50  2016     10         173\n",
       "3      -=yod@=-     217             6.75  2016     10         173\n",
       "4      -=yod@=-     432             7.50  2017      5         173"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract ratings from sqlite database\n",
    "conn = sqlite3.connect(\"../datasets/boardgames/bgg_5yrs_RatingItem.db\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "user_df = pd.read_sql_query(\"\"\"\n",
    "SELECT *,\n",
    "    COUNT(bgg_user_name) OVER\n",
    "         (PARTITION BY bgg_user_name) AS user_count\n",
    "FROM bgg_ratings\n",
    "\n",
    "\"\"\", conn)\n",
    "\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12278237, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "A common problem in recommender systems is known as ***user cold-start***, where it is difficult to recommend items for users with very few number of consumed items (in this case rated board games), due to lack of information to model their preferences. As such, we choose to only keep the users with at least 30 rated board games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10667845, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering dataframe to contain users with at least 30 rates\n",
    "user_df = user_df[user_df['user_count']>=30]\n",
    "user_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to extract the user ratings for the board games that we are left with after extensive EDA and cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9182849, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering dataframe to user ratings of the board games we are concerned with\n",
    "user_df = user_df[user_df['bgg_id'].isin(df['bgg_id'])]\n",
    "user_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9.182849e+06\n",
       "mean     2.552930e+02\n",
       "std      3.462861e+02\n",
       "min      3.000000e+01\n",
       "25%      7.900000e+01\n",
       "50%      1.560000e+02\n",
       "75%      3.160000e+02\n",
       "max      6.717000e+03\n",
       "Name: user_count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df['user_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df as .pkl\n",
    "outfile = open('../datasets/boardgames/bgg_users_2015.pkl', 'wb')\n",
    "pickle.dump(user_df, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Board Game Mapper\n",
    "\n",
    "We require a mapper for board game id to the board game name since our predictions would be done on the board game ids. This mapper will be user at the end after an actual prediction has been made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapper (bgg_id -> name)\n",
    "bg_mapper = {}\n",
    "for i, name in zip(df['bgg_id'], df['name']):\n",
    "    bg_mapper[str(i)] = name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique id  \n",
    "\n",
    "We require to map the board game ids to embedding vectors in the models later. Hence, we need lists of the unique board game ids and unique user ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique users and unique board game ids\n",
    "# Need to keep it as numpy.ndarray\n",
    "unique_user = user_df['bgg_user_name'].unique()\n",
    "unique_bgg_id = df['bgg_id'].unique().astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3', '9', '10', '11', '12', '13', '14', '16', '17', '25'],\n",
       "      dtype='<U21')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_bgg_id[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Model\n",
    "\n",
    "This is a two-tower retrieval model, we will build each tower separately and then combine them in the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and test sets\n",
    "\n",
    "We want to split the user dataframe into train and test sets, by time. The data up to time $T$ would be used to predict user rating after $T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort user dataframe by date\n",
    "user_df = user_df.sort_values(by=['year', 'month']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset with shuffle False\n",
    "# We only need the user name and bgg_id\n",
    "user_train, user_test = train_test_split(user_df[['bgg_id', 'bgg_user_name']], shuffle=False, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>bgg_user_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7346277</th>\n",
       "      <td>267814</td>\n",
       "      <td>nickri1890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7346278</th>\n",
       "      <td>251412</td>\n",
       "      <td>nickrice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bgg_id bgg_user_name\n",
       "7346277  267814    nickri1890\n",
       "7346278  251412      nickrice"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_train.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>bgg_user_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7346279</th>\n",
       "      <td>113294</td>\n",
       "      <td>nickster1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7346280</th>\n",
       "      <td>146021</td>\n",
       "      <td>nickster1970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         bgg_id bgg_user_name\n",
       "7346279  113294  nickster1970\n",
       "7346280  146021  nickster1970"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and test into Tensor Datasets\n",
    "# user_train = user_train.to_dict('records')\n",
    "# user_train = tf.data.Dataset.from_tensor_slices(user_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_test = user_test.to_dict('records')\n",
    "# user_test = tf.data.Dataset.from_tensor_slices(user_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert train and test into Tensor Datasets\n",
    "user_train['bgg_id'] = user_train['bgg_id'].astype(str)\n",
    "user_test['bgg_id'] = user_test['bgg_id'].astype(str)\n",
    "user_train = tf.data.Dataset.from_tensor_slices(user_train).map(lambda x: {'bgg_id': x[0], 'bgg_user_name': x[1]})\n",
    "user_test = tf.data.Dataset.from_tensor_slices(user_test).map(lambda x: {'bgg_id': x[0], 'bgg_user_name': x[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality of the query\n",
    "embedding_dimension = 32\n",
    "\n",
    "# Define the model\n",
    "user_model = Sequential([\n",
    "    StringLookup(vocabulary=unique_user, mask_token=None),\n",
    "    # Additional embedding to account for unknown tokens\n",
    "    Embedding(len(unique_user) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidate tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Embedding(1000, 64))\n",
    "# # The model will take as input an integer matrix of size (batch,\n",
    "# # input_length), and the largest integer (i.e. word index) in the input\n",
    "# # should be no larger than 999 (vocabulary size).\n",
    "# # Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
    "# # dimension.\n",
    "# input_array = np.random.randint(1000, size=(32, 10))\n",
    "# model.compile('rmsprop', 'mse')\n",
    "# output_array = model.predict(input_array)\n",
    "# print(output_array.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model for board game names\n",
    "bg_model = tf.keras.Sequential([\n",
    "    StringLookup(vocabulary=unique_bgg_id, mask_token=None),\n",
    "    Embedding(len(unique_bgg_id) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "In the training data, there are positive (bgg_id, bgg_user_name) pairs. To gauge on how good the model is, we need to compare the affinity score that the model calculates for a particular pair to the scores of all the other possible candidates. In other words, the higher the score for the positive pair as compared to other candidates, the more accurate the model is.\n",
    "\n",
    "We use `FactorizedTopK` metric which requires the dataset of candidates that are used as implicit negatives for evaluation. We are implicitly assuming that if a user did not rate a board game, he/she do not like that board game as much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['bgg_id'].values.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tf.data.Dataset.from_tensor_slices(df['bgg_id'].values.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Tensor Dataset object\n",
    "bgg_ids = tf.data.Dataset.from_tensor_slices(df['bgg_id'].values.astype(str))\n",
    "\n",
    "# The metrics\n",
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=bgg_ids.batch(128).map(bg_model)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss\n",
    "\n",
    "We use the `Retrieval` task object to bundle together the loss function and metric computation. This becomes a Keras layer that takes the embeddings from the two towers as arguments, and returning the computed loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the task\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full model\n",
    "\n",
    "We want to combine all of the above together into a model. We use `tfrs.Model` as the base model which take care of creating the appropriate training loop to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bgg_id': b'113294', 'bgg_user_name': b'nickster1970'}\n",
      "{'bgg_id': b'146021', 'bgg_user_name': b'nickster1970'}\n",
      "{'bgg_id': b'214880', 'bgg_user_name': b'nicktaruffi'}\n",
      "{'bgg_id': b'39856', 'bgg_user_name': b'nickwatt'}\n",
      "{'bgg_id': b'92828', 'bgg_user_name': b'nickwatt'}\n",
      "{'bgg_id': b'218603', 'bgg_user_name': b'nickwatt'}\n",
      "{'bgg_id': b'246784', 'bgg_user_name': b'nickwatt'}\n",
      "{'bgg_id': b'247160', 'bgg_user_name': b'nickwatt'}\n",
      "{'bgg_id': b'24181', 'bgg_user_name': b'nicnied'}\n",
      "{'bgg_id': b'35497', 'bgg_user_name': b'nicnied'}\n",
      "{'bgg_id': b'132372', 'bgg_user_name': b'nicnied'}\n"
     ]
    }
   ],
   "source": [
    "# Check the format of train and test datasets\n",
    "count = 0\n",
    "\n",
    "for element in user_test.as_numpy_iterator():\n",
    "    if count <=10:\n",
    "        print(element)\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model\n",
    "class BGRetrievalModel(tfrs.Model):\n",
    "    \n",
    "    def __init__(self, user_model, bg_model):\n",
    "        super().__init__()\n",
    "        self.bg_model: tf.keras.Model = bg_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "    \n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "        # Picking out the user features and passing them into the user model\n",
    "        # Format of each entry is ['bgg_id', 'bgg_user_name']\n",
    "        user_embeddings = self.user_model(features['bgg_user_name'])\n",
    "        \n",
    "        # Picking out the board games features, passing into bg model\n",
    "        positive_bg_embeddings = self.bg_model(features['bgg_id'])\n",
    "        \n",
    "        # Task computes the loss and the metrics\n",
    "        return self.task(user_embeddings, positive_bg_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and Evaluation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and compile the model\n",
    "retrieval_model = BGRetrievalModel(user_model, bg_model)\n",
    "retrieval_model.compile(optimizer=Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and cache the datasets, did not shuffle to keep time order\n",
    "cached_user_train = user_train.batch(8192).cache()\n",
    "cached_user_test = user_test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n",
      "897/897 [==============================] - 1296s 1s/step - factorized_top_k/top_1_categorical_accuracy: 7.1764e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0075 - factorized_top_k/top_10_categorical_accuracy: 0.0153 - factorized_top_k/top_50_categorical_accuracy: 0.0651 - factorized_top_k/top_100_categorical_accuracy: 0.1127 - loss: 72187.0740 - regularization_loss: 0.0000e+00 - total_loss: 72187.0740\n",
      "Epoch 2/3\n",
      "897/897 [==============================] - 1273s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0011 - factorized_top_k/top_5_categorical_accuracy: 0.0098 - factorized_top_k/top_10_categorical_accuracy: 0.0194 - factorized_top_k/top_50_categorical_accuracy: 0.0779 - factorized_top_k/top_100_categorical_accuracy: 0.1310 - loss: 70259.5668 - regularization_loss: 0.0000e+00 - total_loss: 70259.5668\n",
      "Epoch 3/3\n",
      "897/897 [==============================] - 1280s 1s/step - factorized_top_k/top_1_categorical_accuracy: 0.0013 - factorized_top_k/top_5_categorical_accuracy: 0.0109 - factorized_top_k/top_10_categorical_accuracy: 0.0213 - factorized_top_k/top_50_categorical_accuracy: 0.0826 - factorized_top_k/top_100_categorical_accuracy: 0.1379 - loss: 69382.4697 - regularization_loss: 0.0000e+00 - total_loss: 69382.4697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13c04e727c0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "tf.random.set_seed(42)\n",
    "retrieval_model.fit(cached_user_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449/449 [==============================] - 287s 640ms/step - factorized_top_k/top_1_categorical_accuracy: 9.7138e-04 - factorized_top_k/top_5_categorical_accuracy: 0.0057 - factorized_top_k/top_10_categorical_accuracy: 0.0111 - factorized_top_k/top_50_categorical_accuracy: 0.0471 - factorized_top_k/top_100_categorical_accuracy: 0.0821 - loss: 33129.7995 - regularization_loss: 0.0000e+00 - total_loss: 33129.7995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0009713759645819664,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.005677431356161833,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.011128352954983711,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.04705238714814186,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.08205077797174454,\n",
       " 'loss': 11230.853515625,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 11230.853515625}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "retrieval_model.evaluate(cached_user_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values tell us whether the true positive is in the top-k retrieved items from the entire candidate set. For example, a top-50 categorical accuracy metric of 0.3 means that 30% of the top 50 retrieved items are true positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the metrics, there is a considerable difference between the train and test accuracies, suggesting that the model has been overfitted. It is common since the model has many parameters. A low top-k accuracy would also suggest that the model is recommending board games to users who already rated those board games.\n",
    "\n",
    "(Maybe can try regularization to generalize better to unseen data.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>game_type</th>\n",
       "      <th>designer</th>\n",
       "      <th>artist</th>\n",
       "      <th>publisher</th>\n",
       "      <th>min_players</th>\n",
       "      <th>max_players</th>\n",
       "      <th>min_age</th>\n",
       "      <th>min_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>category</th>\n",
       "      <th>mechanic</th>\n",
       "      <th>rank</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>stddev_rating</th>\n",
       "      <th>bayes_rating</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Samurai</td>\n",
       "      <td>1998</td>\n",
       "      <td>5497</td>\n",
       "      <td>2</td>\n",
       "      <td>11883</td>\n",
       "      <td>17,133,267,29,7340,7335,41,2973,4617,1391,8291...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1009,1035</td>\n",
       "      <td>2080,2040,2026,2846,2004,2002</td>\n",
       "      <td>207.0</td>\n",
       "      <td>14648.0</td>\n",
       "      <td>7.45046</td>\n",
       "      <td>1.18569</td>\n",
       "      <td>7.24774</td>\n",
       "      <td>2.4885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>El Caballero</td>\n",
       "      <td>1998</td>\n",
       "      <td>5497</td>\n",
       "      <td>7,8</td>\n",
       "      <td>74</td>\n",
       "      <td>267,133,3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1020</td>\n",
       "      <td>2080,2002</td>\n",
       "      <td>2679.0</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>6.46354</td>\n",
       "      <td>1.43462</td>\n",
       "      <td>5.94897</td>\n",
       "      <td>3.1824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bgg_id          name  year game_type designer artist  \\\n",
       "0       3       Samurai  1998      5497        2  11883   \n",
       "1       9  El Caballero  1998      5497      7,8     74   \n",
       "\n",
       "                                           publisher min_players max_players  \\\n",
       "0  17,133,267,29,7340,7335,41,2973,4617,1391,8291...           2           4   \n",
       "1                                          267,133,3           2           4   \n",
       "\n",
       "   min_age  min_time  max_time   category                       mechanic  \\\n",
       "0     10.0      30.0      60.0  1009,1035  2080,2040,2026,2846,2004,2002   \n",
       "1     13.0      90.0      90.0       1020                      2080,2002   \n",
       "\n",
       "     rank  num_votes  avg_rating  stddev_rating  bayes_rating  complexity  \n",
       "0   207.0    14648.0     7.45046        1.18569       7.24774      2.4885  \n",
       "1  2679.0     1374.0     6.46354        1.43462       5.94897      3.1824  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Board game dataset needs to be Tensorflow object\n",
    "bgg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x13c7fb745e0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model that takes in raw query features\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(retrieval_model.user_model)\n",
    "\n",
    "# Recommends a board game out of the entire boardgame dataset\n",
    "index.index(bgg_ids.batch(128).map(retrieval_model.bg_model), bgg_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for -johnny-: [b'255675' b'164265' b'123096']\n"
     ]
    }
   ],
   "source": [
    "# Get recommendation\n",
    "_, board_games = index(tf.constant(['-johnny-']))\n",
    "print(f'Recommendations for -johnny-: {board_games[0, :3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to successfully recommend top 3 games (number of games arbituarily decided) to a user with the username '-johnny-' based on the trained embeddings for both the query tower and candidate tower. However, we are recommending the board game id right now, and we want to map that to the board game name for it to be more meaningful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for -johnny-: ['Exit: The Game – The Catacombs of Horror', 'Witness', 'Space Cadets']\n"
     ]
    }
   ],
   "source": [
    "# Map the predicted bgg_id to the board game name\n",
    "named_games = []\n",
    "for bgg_id in board_games[0, :3]:\n",
    "    named_games.append(bg_mapper[bgg_id.numpy().decode(\"utf-8\")])\n",
    "\n",
    "print(f'Recommendations for -johnny-: {named_games}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_user_name</th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>bgg_user_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>user_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>59946</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>166384</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73899</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>150376</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132254</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>150658</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191533</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>478</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191534</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>103885</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354534</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>18833</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354535</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>54307</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056490</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>94</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056491</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>26566</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056492</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>41114</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056493</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>161936</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2016</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016197</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>148261</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2753589</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>223855</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3125592</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>157096</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262569</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>34084</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262570</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>225818</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3432492</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>96848</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553050</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>173442</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912965</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>8935</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912966</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>10093</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912967</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>15987</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912968</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>92415</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912969</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>103886</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912970</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>129622</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912971</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>221107</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>6</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4017364</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>55690</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4128299</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>24509</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4660493</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>119788</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001212</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>903</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5001213</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>118063</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143191</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>203416</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143192</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>203420</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143193</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>264198</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553903</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>37111</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553904</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>173341</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6553905</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>203417</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        bgg_user_name  bgg_id  bgg_user_rating  year  month  user_count\n",
       "1            -johnny-   59946              6.0  2015      1          45\n",
       "2            -johnny-  166384              7.0  2015      1          45\n",
       "73899        -johnny-  150376              6.0  2015      2          45\n",
       "132254       -johnny-  150658              6.0  2015      3          45\n",
       "191533       -johnny-     478              6.0  2015      4          45\n",
       "191534       -johnny-  103885              5.0  2015      4          45\n",
       "354534       -johnny-   18833              9.0  2015      7          45\n",
       "354535       -johnny-   54307              8.0  2015      7          45\n",
       "1056490      -johnny-      94              8.0  2016      4          45\n",
       "1056491      -johnny-   26566              4.0  2016      4          45\n",
       "1056492      -johnny-   41114              8.0  2016      4          45\n",
       "1056493      -johnny-  161936              9.0  2016      4          45\n",
       "2016197      -johnny-  148261              4.0  2017      2          45\n",
       "2753589      -johnny-  223855              4.0  2017      9          45\n",
       "3125592      -johnny-  157096              4.0  2017     12          45\n",
       "3262569      -johnny-   34084              8.0  2018      1          45\n",
       "3262570      -johnny-  225818              3.0  2018      1          45\n",
       "3432492      -johnny-   96848              5.0  2018      2          45\n",
       "3553050      -johnny-  173442              6.0  2018      3          45\n",
       "3912965      -johnny-    8935              9.0  2018      6          45\n",
       "3912966      -johnny-   10093              9.0  2018      6          45\n",
       "3912967      -johnny-   15987              8.0  2018      6          45\n",
       "3912968      -johnny-   92415              9.0  2018      6          45\n",
       "3912969      -johnny-  103886              7.0  2018      6          45\n",
       "3912970      -johnny-  129622              7.0  2018      6          45\n",
       "3912971      -johnny-  221107              9.0  2018      6          45\n",
       "4017364      -johnny-   55690              4.0  2018      7          45\n",
       "4128299      -johnny-   24509              7.0  2018      8          45\n",
       "4660493      -johnny-  119788              5.0  2018     12          45\n",
       "5001212      -johnny-     903              8.0  2019      2          45\n",
       "5001213      -johnny-  118063              6.0  2019      2          45\n",
       "5143191      -johnny-  203416              6.0  2019      3          45\n",
       "5143192      -johnny-  203420              6.0  2019      3          45\n",
       "5143193      -johnny-  264198              5.0  2019      3          45\n",
       "6553903      -johnny-   37111              9.0  2019     12          45\n",
       "6553904      -johnny-  173341              6.0  2019     12          45\n",
       "6553905      -johnny-  203417              6.0  2019     12          45"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if our model is re-recommending the user a game he or she has already played\n",
    "user_df[user_df['bgg_user_name']=='-johnny-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the board games which the user '-johnny-' has rated, we see that the top 3 recommended games are not within them. This is still a good sign, but it may be just so happened that these 45 entries have no false positives. \n",
    "\n",
    "The retrieval model is useful for getting quick recommendations, but it is just based on the board game ids and user ids. This model is usually built to be more computationally efficient to filter out all candidates that the user is not interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking Model\n",
    "\n",
    "The ranking model is built to be used in tandem with the retrieval model, taking the outputs from the retrieval model and finetuning them to select the best possible recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and test sets\n",
    "\n",
    "The train and test data will now include the user ratings to give a sense of ranking to the recommended board games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_train, rating_test = train_test_split(user_df[['bgg_id', 'bgg_user_name', 'bgg_user_rating']], shuffle=False, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and test into Tensor Datasets\n",
    "# tensor_user_train = tf.data.Dataset.from_tensor_slices(rating_train[['bgg_id', 'bgg_user_name']].astype(str))\n",
    "# tensor_user_test = tf.data.Dataset.from_tensor_slices(rating_test[['bgg_id', 'bgg_user_name']].astype(str))\n",
    "# tensor_rating_train = tf.data.Dataset.from_tensor_slices(rating_train['bgg_user_rating'].astype('float32'))\n",
    "# tensor_rating_test = tf.data.Dataset.from_tensor_slices(rating_test['bgg_user_rating'].astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and test into Tensor Datasets\n",
    "rating_train = tf.data.Dataset.from_tensor_slices({'bgg_id': rating_train['bgg_id'].astype(str),\n",
    "                                                  'bgg_user_name': rating_train['bgg_user_name'],\n",
    "                                                  'bgg_user_rating': rating_train['bgg_user_rating'].astype('float32')})\n",
    "rating_test = tf.data.Dataset.from_tensor_slices({'bgg_id': rating_test['bgg_id'].astype(str),\n",
    "                                                  'bgg_user_name': rating_test['bgg_user_name'],\n",
    "                                                  'bgg_user_rating': rating_test['bgg_user_rating'].astype('float32')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: {bgg_id: (), bgg_user_name: (), bgg_user_rating: ()}, types: {bgg_id: tf.string, bgg_user_name: tf.string, bgg_user_rating: tf.float32}>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine\n",
    "# rating_train = tf.data.Dataset.zip((tensor_user_train, tensor_rating_train))\n",
    "# rating_test = tf.data.Dataset.zip((tensor_user_test, tensor_rating_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert train and test into Tensor Datasets\n",
    "# rating_train['bgg_id'] = rating_train['bgg_id'].astype(str)\n",
    "# rating_test['bgg_id'] = rating_test['bgg_id'].astype(str)\n",
    "# # rating_train['bgg_user_rating'] = rating_train['bgg_user_rating'].astype('float32')\n",
    "# # rating_test['bgg_user_rating'] = rating_test['bgg_user_rating'].astype('float32')\n",
    "\n",
    "\n",
    "# rating_train = tf.data.Dataset.from_tensor_slices(rating_train[['bgg_id', 'bgg_user_name']], rating_train['bgg_user_rating'])\n",
    "# rating_test = tf.data.Dataset.from_tensor_slices(rating_test[['bgg_id', 'bgg_user_name']], rating_test['bgg_user_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ranking layers\n",
    "\n",
    "The ranking model is composed of multiple layers for ranking tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ranking tasks\n",
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # User embeddings\n",
    "        self.user_embeddings = Sequential([\n",
    "            StringLookup(vocabulary=unique_user, mask_token=None),\n",
    "            Embedding(len(unique_user) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Board game embeddings\n",
    "        self.bg_embeddings = Sequential([\n",
    "            StringLookup(vocabulary=unique_bgg_id, mask_token=None),\n",
    "            Embedding(len(unique_bgg_id) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Predictions\n",
    "        self.ratings = Sequential([\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            Dense(64, activation=\"relu\"),\n",
    "          # Rating predictions in the final layer.\n",
    "            Dense(1)\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        bgg_user_name, bgg_id = inputs\n",
    "        user_embedding = self.user_embeddings(bgg_user_name)\n",
    "        bg_embedding = self.bg_embeddings(bgg_id)\n",
    "        return self.ratings(tf.concat([user_embedding, bg_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['-johnny-']\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: ['20545']\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.02334006]], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This model takes user names and bgg ids, and outputs a predicted rating\n",
    "RankingModel()((['-johnny-'],['20545']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.01110805]], dtype=float32)>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This model takes user names and bgg ids, and outputs a predicted rating\n",
    "# RankingModel()(tf.convert_to_tensor((['-johnny-'],['20545'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss and metrics\n",
    "\n",
    "This time, we use the `Ranking` task object to put together the loss function and metric computation. The metrics used is `RootMeanSquaredError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loss + metrics task\n",
    "task = tfrs.tasks.Ranking(\n",
    "    loss = MeanSquaredError(),\n",
    "    metrics = [RootMeanSquaredError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full model\n",
    "\n",
    "We want to combine all of the above together into a model. We use `tfrs.Model` as the base model which take care of creating the appropriate training loop to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bgg_id': b'113294', 'bgg_user_name': b'nickster1970', 'bgg_user_rating': 7.0}\n",
      "{'bgg_id': b'146021', 'bgg_user_name': b'nickster1970', 'bgg_user_rating': 8.0}\n",
      "{'bgg_id': b'214880', 'bgg_user_name': b'nicktaruffi', 'bgg_user_rating': 8.0}\n",
      "{'bgg_id': b'39856', 'bgg_user_name': b'nickwatt', 'bgg_user_rating': 7.0}\n",
      "{'bgg_id': b'92828', 'bgg_user_name': b'nickwatt', 'bgg_user_rating': 7.0}\n",
      "{'bgg_id': b'218603', 'bgg_user_name': b'nickwatt', 'bgg_user_rating': 8.0}\n",
      "{'bgg_id': b'246784', 'bgg_user_name': b'nickwatt', 'bgg_user_rating': 8.5}\n",
      "{'bgg_id': b'247160', 'bgg_user_name': b'nickwatt', 'bgg_user_rating': 7.0}\n",
      "{'bgg_id': b'24181', 'bgg_user_name': b'nicnied', 'bgg_user_rating': 9.5}\n",
      "{'bgg_id': b'35497', 'bgg_user_name': b'nicnied', 'bgg_user_rating': 4.0}\n",
      "{'bgg_id': b'132372', 'bgg_user_name': b'nicnied', 'bgg_user_rating': 7.0}\n"
     ]
    }
   ],
   "source": [
    "# Check the format of train and test datasets\n",
    "count = 0\n",
    "for element in rating_test.as_numpy_iterator():\n",
    "    if count <=10:\n",
    "        print(element)\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model\n",
    "class BGRankingModel(tfrs.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel()\n",
    "        # The loss + metrics task\n",
    "        self.task: Layer = tfrs.tasks.Ranking(\n",
    "            loss = MeanSquaredError(),\n",
    "            metrics = [RootMeanSquaredError()]\n",
    "        )\n",
    "    \n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "        rating_predictions = self.ranking_model(\n",
    "            (features['bgg_user_name'], features['bgg_id']))\n",
    "        \n",
    "        # Task computes the loss and the metrics\n",
    "        return self.task(labels=features['bgg_user_rating'], predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and compile the model\n",
    "ranking_model = BGRankingModel()\n",
    "ranking_model.compile(optimizer=Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and cache the datasets, did not shuffle to keep time order\n",
    "cached_rating_train = rating_train.batch(81920).cache()\n",
    "cached_rating_test = rating_test.batch(40960).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bgg_id': b'113294', 'bgg_user_name': b'nickster1970', 'bgg_user_rating': 7.0}\n",
      "{'bgg_id': b'146021', 'bgg_user_name': b'nickster1970', 'bgg_user_rating': 8.0}\n",
      "{'bgg_id': b'214880', 'bgg_user_name': b'nicktaruffi', 'bgg_user_rating': 8.0}\n"
     ]
    }
   ],
   "source": [
    "# Check the format of train and test datasets\n",
    "count = 0\n",
    "for element in rating_test.as_numpy_iterator():\n",
    "    if count <=2:\n",
    "        print(element)\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "90/90 [==============================] - 20s 223ms/step - root_mean_squared_error: 1.9469 - loss: 3.7623 - regularization_loss: 0.0000e+00 - total_loss: 3.7623\n",
      "Epoch 2/3\n",
      "90/90 [==============================] - 12s 136ms/step - root_mean_squared_error: 1.3703 - loss: 1.8766 - regularization_loss: 0.0000e+00 - total_loss: 1.8766\n",
      "Epoch 3/3\n",
      "90/90 [==============================] - 12s 137ms/step - root_mean_squared_error: 1.3553 - loss: 1.8358 - regularization_loss: 0.0000e+00 - total_loss: 1.8358\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13c48911b20>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "tf.random.set_seed(42)\n",
    "ranking_model.fit(cached_rating_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 3s 71ms/step - root_mean_squared_error: 1.3503 - loss: 1.8240 - regularization_loss: 0.0000e+00 - total_loss: 1.8240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 1.3503472805023193,\n",
       " 'loss': 1.8450074195861816,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 1.8450074195861816}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "ranking_model.evaluate(cached_rating_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the rmse and loss are both lower than the train data, there may be some underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Deep Model\n",
    "\n",
    "We want to utilize the vast features we have for the board games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Preprocessing\n",
    "\n",
    "#### Lookup vocabulary\n",
    "\n",
    "We want to define a vocabulary for both board games and users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large number of bins to reduce chance of hash collisions\n",
    "# num_hashing_bins = 200_000\n",
    "# bgg_id_hashing = Hashing(num_bins=num_hashing_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([124101,  90064], dtype=int64)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the layer out with arbituary bgg ids\n",
    "# bgg_id_hashing(['34324', '32432'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary for bgg_id\n",
    "bgg_id_lookup = StringLookup()\n",
    "bgg_id_lookup.adapt(bgg_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7931"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgg_id_lookup.vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([1814,  227,    1], dtype=int64)>"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the layer out with bgg ids\n",
    "# Note that bgg_id = 2 is not in the list\n",
    "bgg_id_lookup(['3', '9', '2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary for user names\n",
    "user_lookup = StringLookup()\n",
    "user_lookup.adapt(tf.data.Dataset.from_tensor_slices(unique_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95598"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_lookup.vocab_size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous features\n",
    "\n",
    "Complexity is an important continuous feature to use in the model. However, the reason it is continuous is that the value reflects the average complexity rating as contributed by the BGG community. We can discretize the complexity to a pre-defined number of buckets, since it is reasonable to assume that board games with very similar complexity will fall within the same range of complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the feature\n",
    "complexity_normalization = Normalization()\n",
    "complexity_normalization.adapt(tf.data.Dataset.from_tensor_slices(df['complexity']).batch(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[ 0.39823163],\n",
       "       [ 1.3151934 ],\n",
       "       [-0.03692577],\n",
       "       [-0.6782308 ],\n",
       "       [ 0.2137556 ]], dtype=float32)>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test normalization\n",
    "complexity_normalization(df['complexity'].values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of discretized buckets\n",
    "# Min complexity is 1, Max is 5\n",
    "complexity_buckets = np.linspace(1, 5, num=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical features\n",
    "\n",
    "Try with game type and category first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom splitting function\n",
    "def split_on_comma(input_data):\n",
    "    return tf.strings.split(input_data, sep=',')\n",
    "\n",
    "max_tokens = 10_000\n",
    "# Vectorization of game types\n",
    "vec_game_types = TextVectorization(max_tokens=max_tokens, standardize=None, split=split_on_comma)\n",
    "vec_game_types.adapt(tf.data.Dataset.from_tensor_slices(df['game_type']).batch(512))\n",
    "\n",
    "# Vectorization of categories\n",
    "vec_categories = TextVectorization(max_tokens=max_tokens, standardize=None, split=split_on_comma)\n",
    "vec_categories.adapt(tf.data.Dataset.from_tensor_slices(df['category']).batch(512))\n",
    "\n",
    "# Vectorization of mechanics\n",
    "vec_mechanics = TextVectorization(max_tokens=max_tokens, standardize=None, split=split_on_comma)\n",
    "vec_mechanics.adapt(tf.data.Dataset.from_tensor_slices(df['mechanic']).batch(512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game type: \"99999\"\n",
      "Vectorized game types: [2]\n",
      "------------------------------\n",
      "Game type: \"4665\"\n",
      "Vectorized game types: [9]\n",
      "------------------------------\n",
      "Game type: \"5496\"\n",
      "Vectorized game types: [6]\n",
      "------------------------------\n",
      "Game type: \"5496\"\n",
      "Vectorized game types: [6]\n",
      "------------------------------\n",
      "Game type: \"4664\"\n",
      "Vectorized game types: [5]\n",
      "------------------------------\n",
      "Game type: \"99999\"\n",
      "Vectorized game types: [2]\n",
      "------------------------------\n",
      "Game type: \"99999\"\n",
      "Vectorized game types: [2]\n",
      "------------------------------\n",
      "Game type: \"99999\"\n",
      "Vectorized game types: [2]\n",
      "------------------------------\n",
      "Game type: \"5496,5498\"\n",
      "Vectorized game types: [6 7]\n",
      "------------------------------\n",
      "Game type: \"5496\"\n",
      "Vectorized game types: [6]\n",
      "------------------------------\n",
      "Game type: \"5498\"\n",
      "Vectorized game types: [7]\n",
      "------------------------------\n",
      "Game type: \"5497\"\n",
      "Vectorized game types: [3]\n",
      "------------------------------\n",
      "Game type: \"5497\"\n",
      "Vectorized game types: [3]\n",
      "------------------------------\n",
      "Game type: \"5496,5499\"\n",
      "Vectorized game types: [6 4]\n",
      "------------------------------\n",
      "Game type: \"5499\"\n",
      "Vectorized game types: [4]\n",
      "------------------------------\n",
      "Game type: \"99999\"\n",
      "Vectorized game types: [2]\n",
      "------------------------------\n",
      "Game type: \"5499\"\n",
      "Vectorized game types: [4]\n",
      "------------------------------\n",
      "Game type: \"99999\"\n",
      "Vectorized game types: [2]\n",
      "------------------------------\n",
      "Game type: \"5497\"\n",
      "Vectorized game types: [3]\n",
      "------------------------------\n",
      "Game type: \"4664\"\n",
      "Vectorized game types: [5]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Testing out the vectorization on game types\n",
    "for value in tf.constant(df['game_type'].sample(20, random_state=42)):\n",
    "    tf.print(\"Game type:\", value)\n",
    "    tf.print(\"Vectorized game types:\", vec_game_types(value))\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: \"1002,1010\"\n",
      "Vectorized categories: [2 3]\n",
      "------------------------------\n",
      "Categories: \"1032,1041,1017,1031\"\n",
      "Vectorized categories: [21 22 6 32]\n",
      "------------------------------\n",
      "Categories: \"1022,1010,1046,1047\"\n",
      "Vectorized categories: [12 3 5 10]\n",
      "------------------------------\n",
      "Categories: \"1064,1016,1019\"\n",
      "Vectorized categories: [28 7 4]\n",
      "------------------------------\n",
      "Categories: \"1023,1102,1019\"\n",
      "Vectorized categories: [13 73 4]\n",
      "------------------------------\n",
      "Categories: \"1021,1010,1008\"\n",
      "Vectorized categories: [8 3 29]\n",
      "------------------------------\n",
      "Categories: \"1017,1031\"\n",
      "Vectorized categories: [6 32]\n",
      "------------------------------\n",
      "Categories: \"1118,1030\"\n",
      "Vectorized categories: [77 9]\n",
      "------------------------------\n",
      "Categories: \"1002,1028,1037\"\n",
      "Vectorized categories: [2 27 23]\n",
      "------------------------------\n",
      "Categories: \"1022,1002,1020,1016\"\n",
      "Vectorized categories: [12 2 17 7]\n",
      "------------------------------\n",
      "Categories: \"1024,1093,1037\"\n",
      "Vectorized categories: [24 35 23]\n",
      "------------------------------\n",
      "Categories: \"1002\"\n",
      "Vectorized categories: [2]\n",
      "------------------------------\n",
      "Categories: \"1021\"\n",
      "Vectorized categories: [8]\n",
      "------------------------------\n",
      "Categories: \"1023,1040\"\n",
      "Vectorized categories: [13 49]\n",
      "------------------------------\n",
      "Categories: \"1002,1029\"\n",
      "Vectorized categories: [2 19]\n",
      "------------------------------\n",
      "Categories: \"1089,1021\"\n",
      "Vectorized categories: [11 8]\n",
      "------------------------------\n",
      "Categories: \"1021\"\n",
      "Vectorized categories: [8]\n",
      "------------------------------\n",
      "Categories: \"1032,1022,1089,1084,1020\"\n",
      "Vectorized categories: [21 12 11 57 17]\n",
      "------------------------------\n",
      "Categories: \"1050,1079,1026,1001\"\n",
      "Vectorized categories: [20 18 31 34]\n",
      "------------------------------\n",
      "Categories: \"1046,1051,1019\"\n",
      "Vectorized categories: [5 60 4]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Testing out the vectorization on categories\n",
    "for value in tf.constant(df['category'].sample(20, random_state=42)):\n",
    "    tf.print(\"Categories:\", value)\n",
    "    tf.print(\"Vectorized categories:\", vec_categories(value))\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mechanics: \"2080,2040\"\n",
      "Vectorized mechanics: [7 2]\n",
      "------------------------------\n",
      "Mechanics: \"2072\"\n",
      "Vectorized mechanics: [3]\n",
      "------------------------------\n",
      "Mechanics: \"2001,2046,2023,2072,2011,2028,2819,2015\"\n",
      "Vectorized mechanics: [11 15 10 ... 32 20 4]\n",
      "------------------------------\n",
      "Mechanics: \"2080,2046,2072,2016,2015\"\n",
      "Vectorized mechanics: [7 15 3 33 4]\n",
      "------------------------------\n",
      "Mechanics: \"2080,2046,2018,2857,2070\"\n",
      "Vectorized mechanics: [7 15 29 79 18]\n",
      "------------------------------\n",
      "Mechanics: \"2013,2072,2813,2002,2663,2015,2082\"\n",
      "Vectorized mechanics: [44 3 65 ... 51 4 13]\n",
      "------------------------------\n",
      "Mechanics: \"99999\"\n",
      "Vectorized mechanics: [31]\n",
      "------------------------------\n",
      "Mechanics: \"2040\"\n",
      "Vectorized mechanics: [2]\n",
      "------------------------------\n",
      "Mechanics: \"2023\"\n",
      "Vectorized mechanics: [10]\n",
      "------------------------------\n",
      "Mechanics: \"2023,2676,2040,2959,2011,2822,2819,2027,2015\"\n",
      "Vectorized mechanics: [10 12 2 ... 20 37 4]\n",
      "------------------------------\n",
      "Mechanics: \"2893,2023,2072,2676,2040,2028\"\n",
      "Vectorized mechanics: [54 10 3 12 2 32]\n",
      "------------------------------\n",
      "Mechanics: \"2041,2023,2015\"\n",
      "Vectorized mechanics: [6 10 4]\n",
      "------------------------------\n",
      "Mechanics: \"2689,2080,2082\"\n",
      "Vectorized mechanics: [34 7 13]\n",
      "------------------------------\n",
      "Mechanics: \"2040,2960,2686\"\n",
      "Vectorized mechanics: [2 106 19]\n",
      "------------------------------\n",
      "Mechanics: \"2023,2664,2040,2047,2020,2819\"\n",
      "Vectorized mechanics: [10 16 2 27 14 20]\n",
      "------------------------------\n",
      "Mechanics: \"2011,2002,2082\"\n",
      "Vectorized mechanics: [8 9 13]\n",
      "------------------------------\n",
      "Mechanics: \"2012,2040,2047,2020\"\n",
      "Vectorized mechanics: [17 2 27 14]\n",
      "------------------------------\n",
      "Mechanics: \"2023\"\n",
      "Vectorized mechanics: [10]\n",
      "------------------------------\n",
      "Mechanics: \"2080,2017\"\n",
      "Vectorized mechanics: [7 39]\n",
      "------------------------------\n",
      "Mechanics: \"2026,2070\"\n",
      "Vectorized mechanics: [23 18]\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Testing out the vectorization on mechanics\n",
    "for value in tf.constant(df['mechanic'].sample(20, random_state=42)):\n",
    "    tf.print(\"Mechanics:\", value)\n",
    "    tf.print(\"Vectorized mechanics:\", vec_mechanics(value))\n",
    "    print('------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2685', '99999', '2028', '2016', '2689']"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use to get the vocabulary for a vectorizer\n",
    "vec_mechanics.get_vocabulary()[30:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_user_name</th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>bgg_user_rating</th>\n",
       "      <th>year_x</th>\n",
       "      <th>month</th>\n",
       "      <th>user_count</th>\n",
       "      <th>name</th>\n",
       "      <th>year_y</th>\n",
       "      <th>game_type</th>\n",
       "      <th>designer</th>\n",
       "      <th>...</th>\n",
       "      <th>min_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>category</th>\n",
       "      <th>mechanic</th>\n",
       "      <th>rank</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>stddev_rating</th>\n",
       "      <th>bayes_rating</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-=yod@=-</td>\n",
       "      <td>160495</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>ZhanGuo</td>\n",
       "      <td>2014</td>\n",
       "      <td>5497</td>\n",
       "      <td>12293,12294</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1050</td>\n",
       "      <td>2080,2040</td>\n",
       "      <td>509.0</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>7.59899</td>\n",
       "      <td>1.25726</td>\n",
       "      <td>6.86182</td>\n",
       "      <td>3.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>59946</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>Dungeons &amp; Dragons: Castle Ravenloft Board Game</td>\n",
       "      <td>2010</td>\n",
       "      <td>5496</td>\n",
       "      <td>2746,15913,13108,3944</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1022,1020,1010,1046,1024,1047</td>\n",
       "      <td>2023,2072,2676,2011,2028,2819,2015</td>\n",
       "      <td>756.0</td>\n",
       "      <td>8363.0</td>\n",
       "      <td>6.97652</td>\n",
       "      <td>1.43756</td>\n",
       "      <td>6.66732</td>\n",
       "      <td>2.5111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>166384</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>Spyfall</td>\n",
       "      <td>2014</td>\n",
       "      <td>5498</td>\n",
       "      <td>78199</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1023,1039,1079,1030,1081</td>\n",
       "      <td>2073,2047,2028,2892,2866,2814,2017</td>\n",
       "      <td>631.0</td>\n",
       "      <td>17970.0</td>\n",
       "      <td>6.89022</td>\n",
       "      <td>1.40803</td>\n",
       "      <td>6.76383</td>\n",
       "      <td>1.2434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-mide-</td>\n",
       "      <td>20545</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>Rory's Story Cubes</td>\n",
       "      <td>2005</td>\n",
       "      <td>5498,5499</td>\n",
       "      <td>6409</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1017</td>\n",
       "      <td>2023,2072,2060,2027</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>3145.0</td>\n",
       "      <td>6.30261</td>\n",
       "      <td>1.55489</td>\n",
       "      <td>6.00793</td>\n",
       "      <td>1.1329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-mide-</td>\n",
       "      <td>145639</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>Coconuts</td>\n",
       "      <td>2013</td>\n",
       "      <td>4665,5499</td>\n",
       "      <td>69564</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1032,1089,1041</td>\n",
       "      <td>2661,2686</td>\n",
       "      <td>919.0</td>\n",
       "      <td>3630.0</td>\n",
       "      <td>7.03525</td>\n",
       "      <td>1.28321</td>\n",
       "      <td>6.55872</td>\n",
       "      <td>1.0429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-toni-</td>\n",
       "      <td>1927</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>Munchkin</td>\n",
       "      <td>2001</td>\n",
       "      <td>5496</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1002,1010,1046,1079</td>\n",
       "      <td>2040,2686,2015</td>\n",
       "      <td>4371.0</td>\n",
       "      <td>40956.0</td>\n",
       "      <td>5.90224</td>\n",
       "      <td>1.83025</td>\n",
       "      <td>5.73034</td>\n",
       "      <td>1.8011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-toni-</td>\n",
       "      <td>4095</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>Star Munchkin</td>\n",
       "      <td>2002</td>\n",
       "      <td>5496</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1002,1046,1079,1016</td>\n",
       "      <td>2041,2072,2686,2008,2015</td>\n",
       "      <td>3103.0</td>\n",
       "      <td>4603.0</td>\n",
       "      <td>6.11641</td>\n",
       "      <td>1.65982</td>\n",
       "      <td>5.86991</td>\n",
       "      <td>1.7437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-toni-</td>\n",
       "      <td>12194</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>Munchkin Bites!</td>\n",
       "      <td>2004</td>\n",
       "      <td>5496,5498</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1002,1046,1024,1079</td>\n",
       "      <td>2072,2008,2015</td>\n",
       "      <td>4149.0</td>\n",
       "      <td>2889.0</td>\n",
       "      <td>5.99423</td>\n",
       "      <td>1.68530</td>\n",
       "      <td>5.74758</td>\n",
       "      <td>1.7563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-toni-</td>\n",
       "      <td>25071</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>Munchkin Cthulhu</td>\n",
       "      <td>2007</td>\n",
       "      <td>5496</td>\n",
       "      <td>12552,22</td>\n",
       "      <td>...</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1002,1046,1024,1079</td>\n",
       "      <td>2072,2008,2015</td>\n",
       "      <td>2736.0</td>\n",
       "      <td>4914.0</td>\n",
       "      <td>6.20680</td>\n",
       "      <td>1.68922</td>\n",
       "      <td>5.93801</td>\n",
       "      <td>1.7082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0b1_ita</td>\n",
       "      <td>4491</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>250</td>\n",
       "      <td>Cave Troll</td>\n",
       "      <td>2002</td>\n",
       "      <td>5496,5497</td>\n",
       "      <td>222</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1010</td>\n",
       "      <td>2001,2080,2040,2078,2015</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>3590.0</td>\n",
       "      <td>6.40988</td>\n",
       "      <td>1.25440</td>\n",
       "      <td>6.10913</td>\n",
       "      <td>1.9784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  bgg_user_name  bgg_id  bgg_user_rating  year_x  month  user_count  \\\n",
       "0      -=yod@=-  160495              7.5    2015      1         173   \n",
       "1      -johnny-   59946              6.0    2015      1          45   \n",
       "2      -johnny-  166384              7.0    2015      1          45   \n",
       "3        -mide-   20545              6.0    2015      1         130   \n",
       "4        -mide-  145639              7.0    2015      1         130   \n",
       "5        -toni-    1927              5.0    2015      1         123   \n",
       "6        -toni-    4095              5.0    2015      1         123   \n",
       "7        -toni-   12194              5.0    2015      1         123   \n",
       "8        -toni-   25071              5.0    2015      1         123   \n",
       "9       0b1_ita    4491              7.0    2015      1         250   \n",
       "\n",
       "                                              name  year_y  game_type  \\\n",
       "0                                          ZhanGuo    2014       5497   \n",
       "1  Dungeons & Dragons: Castle Ravenloft Board Game    2010       5496   \n",
       "2                                          Spyfall    2014       5498   \n",
       "3                               Rory's Story Cubes    2005  5498,5499   \n",
       "4                                         Coconuts    2013  4665,5499   \n",
       "5                                         Munchkin    2001       5496   \n",
       "6                                    Star Munchkin    2002       5496   \n",
       "7                                  Munchkin Bites!    2004  5496,5498   \n",
       "8                                 Munchkin Cthulhu    2007       5496   \n",
       "9                                       Cave Troll    2002  5496,5497   \n",
       "\n",
       "                designer  ... min_time max_time  \\\n",
       "0            12293,12294  ...     60.0    120.0   \n",
       "1  2746,15913,13108,3944  ...     60.0     60.0   \n",
       "2                  78199  ...     15.0     15.0   \n",
       "3                   6409  ...     20.0     20.0   \n",
       "4                  69564  ...     20.0     20.0   \n",
       "5                     22  ...     60.0    120.0   \n",
       "6                     22  ...     90.0     90.0   \n",
       "7                     22  ...     90.0     90.0   \n",
       "8               12552,22  ...     90.0     90.0   \n",
       "9                    222  ...     20.0     60.0   \n",
       "\n",
       "                        category                            mechanic    rank  \\\n",
       "0                           1050                           2080,2040   509.0   \n",
       "1  1022,1020,1010,1046,1024,1047  2023,2072,2676,2011,2028,2819,2015   756.0   \n",
       "2       1023,1039,1079,1030,1081  2073,2047,2028,2892,2866,2814,2017   631.0   \n",
       "3                           1017                 2023,2072,2060,2027  2375.0   \n",
       "4                 1032,1089,1041                           2661,2686   919.0   \n",
       "5            1002,1010,1046,1079                      2040,2686,2015  4371.0   \n",
       "6            1002,1046,1079,1016            2041,2072,2686,2008,2015  3103.0   \n",
       "7            1002,1046,1024,1079                      2072,2008,2015  4149.0   \n",
       "8            1002,1046,1024,1079                      2072,2008,2015  2736.0   \n",
       "9                           1010            2001,2080,2040,2078,2015  1975.0   \n",
       "\n",
       "   num_votes  avg_rating stddev_rating bayes_rating  complexity  \n",
       "0     2850.0     7.59899       1.25726      6.86182      3.8333  \n",
       "1     8363.0     6.97652       1.43756      6.66732      2.5111  \n",
       "2    17970.0     6.89022       1.40803      6.76383      1.2434  \n",
       "3     3145.0     6.30261       1.55489      6.00793      1.1329  \n",
       "4     3630.0     7.03525       1.28321      6.55872      1.0429  \n",
       "5    40956.0     5.90224       1.83025      5.73034      1.8011  \n",
       "6     4603.0     6.11641       1.65982      5.86991      1.7437  \n",
       "7     2889.0     5.99423       1.68530      5.74758      1.7563  \n",
       "8     4914.0     6.20680       1.68922      5.93801      1.7082  \n",
       "9     3590.0     6.40988       1.25440      6.10913      1.9784  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge dataframes\n",
    "combined_df = user_df.merge(df, how='left', on='bgg_id')\n",
    "combined_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "combined_train, combined_test = train_test_split(combined_df[['bgg_id', 'bgg_user_name', 'bgg_user_rating', 'complexity', 'game_type', 'category', 'mechanic']], shuffle=False, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert train and test into Tensor Datasets\n",
    "combined_train = tf.data.Dataset.from_tensor_slices({'bgg_id': combined_train['bgg_id'].astype(str),\n",
    "                                                     'bgg_user_name': combined_train['bgg_user_name'],\n",
    "                                                     'bgg_user_rating': combined_train['bgg_user_rating'].astype('float32'),\n",
    "                                                     'complexity': combined_train['complexity'].astype('float32'),\n",
    "                                                     'game_type': combined_train['game_type'],\n",
    "                                                     'category': combined_train['category'],\n",
    "                                                     'mechanic': combined_train['mechanic']\n",
    "                                                    })\n",
    "combined_test = tf.data.Dataset.from_tensor_slices({'bgg_id': combined_test['bgg_id'].astype(str),\n",
    "                                                    'bgg_user_name': combined_test['bgg_user_name'],\n",
    "                                                    'bgg_user_rating': combined_test['bgg_user_rating'].astype('float32'),\n",
    "                                                    'complexity': combined_test['complexity'].astype('float32'),\n",
    "                                                    'game_type': combined_test['game_type'],\n",
    "                                                    'category': combined_test['category'],\n",
    "                                                    'mechanic': combined_test['mechanic']\n",
    "                                                   })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings\n",
    "\n",
    "Define the embedding layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "# Embedding for bgg_id\n",
    "bgg_id_embedding = Embedding(input_dim=bgg_id_lookup.vocab_size(),\n",
    "                            output_dim=embedding_dimension)\n",
    "\n",
    "# Embedding for user names\n",
    "user_embedding = Embedding(input_dim=user_lookup.vocab_size(),\n",
    "                          output_dim=embedding_dimension)\n",
    "\n",
    "# Embedding for complexity\n",
    "complexity_embedding = Embedding(input_dim=len(complexity_buckets) + 1,\n",
    "                                output_dim=embedding_dimension)\n",
    "\n",
    "# Embeddings for categorial features\n",
    "game_type_embedding = Embedding(max_tokens, embedding_dimension, mask_zero=True)\n",
    "category_embedding = Embedding(max_tokens, embedding_dimension, mask_zero=True)\n",
    "mechanic_embedding = Embedding(max_tokens, embedding_dimension, mask_zero=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for bgg_id\n",
    "bgg_id_model = Sequential([bgg_id_lookup, bgg_id_embedding])\n",
    "\n",
    "# Model for user names\n",
    "user_name_model = Sequential([user_lookup, user_embedding])\n",
    "\n",
    "# Model for complexity\n",
    "complexity_model = Sequential([complexity_embedding, complexity_normalization])\n",
    "\n",
    "# Model for categorical features\n",
    "game_type_model = Sequential([vec_game_types, game_type_embedding, GlobalAveragePooling1D()])\n",
    "category_model = Sequential([vec_categories, category_embedding, GlobalAveragePooling1D()])\n",
    "mechanic_model = Sequential([vec_mechanics, mechanic_embedding, GlobalAveragePooling1D()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User model\n",
    "class UserModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.user_embedding: tf.keras.Model = user_name_model\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        return tf.concat([\n",
    "            self.user_embedding(inputs['bgg_user_name'])\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Board game model\n",
    "class BoardGameModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bgg_id_embedding: tf.keras.Model = bgg_id_model\n",
    "        self.complexity_embedding: tf.keras.Model = complexity_model\n",
    "        self.game_type_embedding: tf.keras.Model = game_type_model\n",
    "        self.category_embedding: tf.keras.Model = category_model\n",
    "        self.mechanic_embedding: tf.keras.Model = mechanic_model\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        return tf.concat([\n",
    "            self.bgg_id_embedding(inputs['bgg_id']),\n",
    "            self.complexity_embedding(inputs['complexity']),\n",
    "            self.game_type_embedding(inputs['game_type']),\n",
    "            self.category_embedding(inputs['category']),\n",
    "            self.mechanic_embedding(inputs['mechanic'])\n",
    "        ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query & Candidate towers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query model\n",
    "class QueryModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding_model = UserModel()\n",
    "        self.dense_layers = Sequential([\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(32)\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate model\n",
    "class CandidateModel(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.embedding_model = BoardGameModel()\n",
    "        self.dense_layers = Sequential([\n",
    "            Dense(64, activation=\"relu\"),\n",
    "            Dense(32)\n",
    "        ])\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        feature_embedding = self.embedding_model(inputs)\n",
    "        return self.dense_layers(feature_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_candidates = tf.data.Dataset.from_tensor_slices({'bgg_id': df['bgg_id'].astype(str),\n",
    "                                                        'complexity': df['complexity'].astype('float32'),\n",
    "                                                        'game_type': df['game_type'],\n",
    "                                                        'category': df['category'],\n",
    "                                                        'mechanic': df['mechanic']\n",
    "                                                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bgg_id': b'113294', 'bgg_user_name': b'nickster1970', 'bgg_user_rating': 7.0, 'complexity': 1.4813, 'game_type': b'5499', 'category': b'1022,1017,1072,1020,1037', 'mechanic': b'2023,2072,2882,2676,2011,2661,2870,2831,2035,2819,2002'}\n",
      "{'bgg_id': b'146021', 'bgg_user_name': b'nickster1970', 'bgg_user_rating': 8.0, 'complexity': 3.3192, 'game_type': b'5496', 'category': b'1022,1010,1046,1024,1093,1097', 'mechanic': b'2001,2023,2072,2078,2028,2819,2853,2015'}\n",
      "{'bgg_id': b'214880', 'bgg_user_name': b'nicktaruffi', 'bgg_user_rating': 8.0, 'complexity': 4.042, 'game_type': b'5497', 'category': b'1021,1094,1088', 'mechanic': b'2013,2911,2005,2002,2015,2082'}\n",
      "{'bgg_id': b'39856', 'bgg_user_name': b'nickwatt', 'bgg_user_rating': 7.0, 'complexity': 1.2203, 'game_type': b'5498', 'category': b'1002,1079,1030', 'mechanic': b'2020,2027,2866,2017'}\n",
      "{'bgg_id': b'92828', 'bgg_user_name': b'nickwatt', 'bgg_user_rating': 7.0, 'complexity': 1.1943, 'game_type': b'5498', 'category': b'1002,1079,1030', 'mechanic': b'2027,2017'}\n",
      "{'bgg_id': b'218603', 'bgg_user_name': b'nickwatt', 'bgg_user_rating': 8.0, 'complexity': 2.2785, 'game_type': b'4666,5499', 'category': b'1009,1084', 'mechanic': b'2001,2080,2957,2875,2026'}\n"
     ]
    }
   ],
   "source": [
    "# Check the format of train and test datasets\n",
    "count = 0\n",
    "for element in combined_test.as_numpy_iterator():\n",
    "    if count <=5:\n",
    "        print(element)\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model\n",
    "class BGDeepModel(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.query_model = QueryModel()\n",
    "        self.candidate_model = CandidateModel()\n",
    "        self.retrieval_task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=tensor_candidates.batch(128).map(self.candidate_model)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def compute_loss(self, features, training=False):\n",
    "        query_embeddings = self.query_model({\n",
    "            'bgg_user_name': features['bgg_user_name']\n",
    "        })\n",
    "        candidate_embeddings = self.candidate_model({\n",
    "            'bgg_id': features['bgg_id'],\n",
    "            'complexity': features['complexity'],\n",
    "            'game_type': features['game_type'],\n",
    "            'category': features['category'],\n",
    "            'mechanic': features['mechanic']\n",
    "        })\n",
    "\n",
    "        return self.retrieval_task(query_embeddings, candidate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: {bgg_id: (None,), bgg_user_name: (None,), bgg_user_rating: (None,), complexity: (None,), game_type: (None,), category: (None,), mechanic: (None,)}, types: {bgg_id: tf.string, bgg_user_name: tf.string, bgg_user_rating: tf.float32, complexity: tf.float32, game_type: tf.string, category: tf.string, mechanic: tf.string}>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_combined_train.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and cache the datasets, did not shuffle to keep time order\n",
    "cached_combined_train = combined_train.batch(16_384).cache()\n",
    "cached_combined_test = combined_test.batch(8192).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input Tensor(\"embedding_26_input_1:0\", shape=(None, None), dtype=float32), but it was called on an input with incompatible shape (None,).\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input Tensor(\"embedding_26_input_1:0\", shape=(None, None), dtype=float32), but it was called on an input with incompatible shape (None,).\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input Tensor(\"embedding_26_input_1:0\", shape=(None, None), dtype=float32), but it was called on an input with incompatible shape (None,).\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int32\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['counter:0'] when minimizing the loss.\n",
      "2/2 [==============================] - 3s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.0071 - factorized_top_k/top_10_categorical_accuracy: 0.0133 - factorized_top_k/top_50_categorical_accuracy: 0.0503 - factorized_top_k/top_100_categorical_accuracy: 0.0790 - loss: 171513.9479 - regularization_loss: 0.0000e+00 - total_loss: 171513.9479\n",
      "Epoch 2/3\n",
      "2/2 [==============================] - 3s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 330554.2031 - regularization_loss: 0.0000e+00 - total_loss: 330554.2031\n",
      "Epoch 3/3\n",
      "2/2 [==============================] - 3s 2s/step - factorized_top_k/top_1_categorical_accuracy: 1.2207e-04 - factorized_top_k/top_5_categorical_accuracy: 6.4087e-04 - factorized_top_k/top_10_categorical_accuracy: 0.0016 - factorized_top_k/top_50_categorical_accuracy: 0.0108 - factorized_top_k/top_100_categorical_accuracy: 0.0183 - loss: 202094.4167 - regularization_loss: 0.0000e+00 - total_loss: 202094.4167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13c156641c0>"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and compile model\n",
    "deep_model = BGDeepModel()\n",
    "deep_model.compile(optimizer=Adagrad(0.1))\n",
    "\n",
    "# Training the model\n",
    "tf.random.set_seed(42)\n",
    "deep_model.fit(cached_combined_train.take(2), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input Tensor(\"embedding_26_input_1:0\", shape=(None, None), dtype=float32), but it was called on an input with incompatible shape (None,).\n",
      "2/2 [==============================] - 1s 591ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.8311e-04 - factorized_top_k/top_10_categorical_accuracy: 3.0518e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0024 - factorized_top_k/top_100_categorical_accuracy: 0.0057 - loss: 74874.9740 - regularization_loss: 0.0000e+00 - total_loss: 74874.9740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.0,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.00018310546875,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.00030517578125,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.00238037109375,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.00567626953125,\n",
       " 'loss': 74855.578125,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 74855.578125}"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "deep_model.evaluate(cached_combined_test.take(2), return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None) for input Tensor(\"embedding_26_input_1:0\", shape=(None, None), dtype=float32), but it was called on an input with incompatible shape (None,).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x13c15664ee0>"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a model that takes in raw query features\n",
    "deep_index = tfrs.layers.factorized_top_k.BruteForce(deep_model.query_model)\n",
    "\n",
    "# Recommends a board game out of the entire boardgame dataset\n",
    "deep_index.index(tensor_candidates.batch(128).map(deep_model.candidate_model), bgg_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TensorSliceDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-388-e708ead18016>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get recommendation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mboard_games\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeep_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'bgg_user_name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'-johnny-'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Recommendations for -johnny-: {board_games[0, :3]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_recommenders\\layers\\factorized_top_k.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, queries, k)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_model\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m       \u001b[0mqueries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_candidates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-359-9399293a66af>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mfeature_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-358-760b48419a14>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         return tf.concat([\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bgg_user_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         ], axis=1)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TensorSliceDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Get recommendation\n",
    "_, board_games = deep_index(tf.data.Dataset.from_tensor_slices({'bgg_user_name': ['-johnny-']}))\n",
    "print(f'Recommendations for -johnny-: {board_games[0, :3]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 'bgg_user_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-390-f244d2fb67e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdeep_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'-johnny-'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_recommenders\\layers\\factorized_top_k.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, queries, k)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_model\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m       \u001b[0mqueries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_candidates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-359-9399293a66af>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mfeature_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-358-760b48419a14>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         return tf.concat([\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bgg_user_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         ], axis=1)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[1;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[0;32m    984\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m<<\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0m_check_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m       \u001b[0mbegin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[0mend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36m_check_index\u001b[1;34m(idx)\u001b[0m\n\u001b[0;32m    863\u001b[0m     \u001b[1;31m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[1;31m# will break `_slice_helper` contract.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_SLICE_TYPE_ERROR\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\", got {!r}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got 'bgg_user_name'"
     ]
    }
   ],
   "source": [
    "deep_index(np.array(['-johnny-']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tasks\n",
    "\n",
    "We are building a multitask recommender, consisting of a retrieval task and rating task. The rating task predicts the ratings as accurately as possible, the retrieval task predicts which board games the user will play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating task\n",
    "rating_task = tfrs.tasks.Ranking(loss = MeanSquaredError(), metrics = [RootMeanSquaredError()])\n",
    "\n",
    "# Retrieval task\n",
    "retrieval_task = tfrs.tasks.Retrieval(metrics = tfrs.metrics.FactorizedTopK(\n",
    "                                        candidates = bgg_ids.batch(256).map(bgg_id_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model\n",
    "class BGDeepModel_old(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "        \n",
    "        # User and board game models\n",
    "        self.user_model: tf.keras.Model = user_name_model\n",
    "        self.bgg_id_model: tf.keras.Model = bgg_id_model\n",
    "        self.complexity_model: tf.keras.Model = complexity_model\n",
    "        self.game_type_model: tf.keras.Model = game_type_model\n",
    "        self.category_model: tf.keras.Model = category_model\n",
    "        self.mechanic_model: tf.keras.Model = mechanic_model\n",
    "            \n",
    "        # Model to take in user and board game embeddings and predict ratings\n",
    "        self.rating_model = Sequential([\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        \n",
    "        # Tasks\n",
    "        self.rating_task: Layer = rating_task\n",
    "        self.retrieval_task: Layer = retrieval_task\n",
    "        \n",
    "        # Loss weights\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "        \n",
    "    def call(self, features) -> tf.Tensor:\n",
    "        user_embeddings = self.user_model(features['bgg_user_name'])\n",
    "        bgg_id_embeddings = self.bgg_id_model(features['bgg_id'])\n",
    "#         complexity_embeddings = self.complexity_model(features['complexity'])\n",
    "#         game_type_embeddings = self.game_type_model(features['game_type'])\n",
    "#         category_embeddings = self.category_model(features['category'])\n",
    "#         mechanic_embeddings = self.mechanic_model(features['mechanic'])\n",
    "        \n",
    "        return (\n",
    "            user_embeddings,\n",
    "            bgg_id_embeddings,\n",
    "#             complexity_embeddings,\n",
    "#             game_type_embeddings,\n",
    "#             category_embeddings,\n",
    "#             mechanic_embeddings,\n",
    "            self.rating_model(tf.concat([user_embeddings, bgg_id_embeddings], axis=1)) )\n",
    "#                                          complexity_embeddings, \n",
    "#                                         game_type_embeddings, category_embeddings, mechanic_embeddings], axis=1))\n",
    "#         )\n",
    "    \n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "        ratings = features['bgg_user_rating']\n",
    "        user_embeddings, bgg_id_embeddings, rating_predictions = self(features)\n",
    "        # , complexity_embeddings, game_type_embeddings, category_embeddings, mechanic_embeddings,\n",
    "        \n",
    "        # Compute loss for each task\n",
    "        rating_loss = self.rating_task(labels=ratings, predictions=rating_predictions)\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, bgg_id_embeddings)\n",
    "#                                              , complexity_embeddings, \n",
    "#                                              game_type_embeddings, category_embeddings, mechanic_embeddings)\n",
    "        \n",
    "        #Combine them using the loss weights\n",
    "        return (self.rating_weight * rating_loss + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and compile model\n",
    "deep_model_old = BGDeepModel_old(rating_weight=1, retrieval_weight=1)\n",
    "deep_model_old.compile(optimizer=Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "449/449 [==============================] - 1305s 3s/step - root_mean_squared_error: 1.4342 - factorized_top_k/top_1_categorical_accuracy: 0.0021 - factorized_top_k/top_5_categorical_accuracy: 0.0099 - factorized_top_k/top_10_categorical_accuracy: 0.0183 - factorized_top_k/top_50_categorical_accuracy: 0.0702 - factorized_top_k/top_100_categorical_accuracy: 0.1192 - loss: 155309.1612 - regularization_loss: 0.0000e+00 - total_loss: 155309.1612\n",
      "Epoch 2/3\n",
      "449/449 [==============================] - 1279s 3s/step - root_mean_squared_error: 1.3449 - factorized_top_k/top_1_categorical_accuracy: 0.0022 - factorized_top_k/top_5_categorical_accuracy: 0.0115 - factorized_top_k/top_10_categorical_accuracy: 0.0217 - factorized_top_k/top_50_categorical_accuracy: 0.0824 - factorized_top_k/top_100_categorical_accuracy: 0.1367 - loss: 151417.1037 - regularization_loss: 0.0000e+00 - total_loss: 151417.1037\n",
      "Epoch 3/3\n",
      "449/449 [==============================] - 1277s 3s/step - root_mean_squared_error: 1.3258 - factorized_top_k/top_1_categorical_accuracy: 0.0025 - factorized_top_k/top_5_categorical_accuracy: 0.0127 - factorized_top_k/top_10_categorical_accuracy: 0.0236 - factorized_top_k/top_50_categorical_accuracy: 0.0868 - factorized_top_k/top_100_categorical_accuracy: 0.1432 - loss: 149622.9443 - regularization_loss: 0.0000e+00 - total_loss: 149622.9443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13c50a43c70>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "tf.random.set_seed(42)\n",
    "deep_model_old.fit(cached_combined_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the summaries of the models\n",
    "# print('bgg_id model\\n')\n",
    "# bgg_id_model().compile(optimizers=Adagrad(0.1)).summary()\n",
    "# print('\\nuser_name model\\n')\n",
    "# user_name_model.summary()\n",
    "# print('\\n complexity model\\n')\n",
    "# complexity_model.summary()\n",
    "# print('\\n game_type model\\n')\n",
    "# game_type_model.summary()\n",
    "# print('\\n category model\\n')\n",
    "# category_model.summary()\n",
    "# print('\\n mechanic model\\n')\n",
    "# mechanic_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_user_name</th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>bgg_user_rating</th>\n",
       "      <th>year_x</th>\n",
       "      <th>month</th>\n",
       "      <th>user_count</th>\n",
       "      <th>name</th>\n",
       "      <th>year_y</th>\n",
       "      <th>game_type</th>\n",
       "      <th>designer</th>\n",
       "      <th>...</th>\n",
       "      <th>min_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>category</th>\n",
       "      <th>mechanic</th>\n",
       "      <th>rank</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>stddev_rating</th>\n",
       "      <th>bayes_rating</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-=yod@=-</td>\n",
       "      <td>160495</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>ZhanGuo</td>\n",
       "      <td>2014</td>\n",
       "      <td>5497</td>\n",
       "      <td>12293,12294</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1050</td>\n",
       "      <td>2080,2040</td>\n",
       "      <td>509.0</td>\n",
       "      <td>2850.0</td>\n",
       "      <td>7.59899</td>\n",
       "      <td>1.25726</td>\n",
       "      <td>6.86182</td>\n",
       "      <td>3.8333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>59946</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>Dungeons &amp; Dragons: Castle Ravenloft Board Game</td>\n",
       "      <td>2010</td>\n",
       "      <td>5496</td>\n",
       "      <td>2746,15913,13108,3944</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1022,1020,1010,1046,1024,1047</td>\n",
       "      <td>2023,2072,2676,2011,2028,2819,2015</td>\n",
       "      <td>756.0</td>\n",
       "      <td>8363.0</td>\n",
       "      <td>6.97652</td>\n",
       "      <td>1.43756</td>\n",
       "      <td>6.66732</td>\n",
       "      <td>2.5111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-johnny-</td>\n",
       "      <td>166384</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>Spyfall</td>\n",
       "      <td>2014</td>\n",
       "      <td>5498</td>\n",
       "      <td>78199</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1023,1039,1079,1030,1081</td>\n",
       "      <td>2073,2047,2028,2892,2866,2814,2017</td>\n",
       "      <td>631.0</td>\n",
       "      <td>17970.0</td>\n",
       "      <td>6.89022</td>\n",
       "      <td>1.40803</td>\n",
       "      <td>6.76383</td>\n",
       "      <td>1.2434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-mide-</td>\n",
       "      <td>20545</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>Rory's Story Cubes</td>\n",
       "      <td>2005</td>\n",
       "      <td>5498,5499</td>\n",
       "      <td>6409</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1017</td>\n",
       "      <td>2023,2072,2060,2027</td>\n",
       "      <td>2375.0</td>\n",
       "      <td>3145.0</td>\n",
       "      <td>6.30261</td>\n",
       "      <td>1.55489</td>\n",
       "      <td>6.00793</td>\n",
       "      <td>1.1329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-mide-</td>\n",
       "      <td>145639</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>Coconuts</td>\n",
       "      <td>2013</td>\n",
       "      <td>4665,5499</td>\n",
       "      <td>69564</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1032,1089,1041</td>\n",
       "      <td>2661,2686</td>\n",
       "      <td>919.0</td>\n",
       "      <td>3630.0</td>\n",
       "      <td>7.03525</td>\n",
       "      <td>1.28321</td>\n",
       "      <td>6.55872</td>\n",
       "      <td>1.0429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  bgg_user_name  bgg_id  bgg_user_rating  year_x  month  user_count  \\\n",
       "0      -=yod@=-  160495              7.5    2015      1         173   \n",
       "1      -johnny-   59946              6.0    2015      1          45   \n",
       "2      -johnny-  166384              7.0    2015      1          45   \n",
       "3        -mide-   20545              6.0    2015      1         130   \n",
       "4        -mide-  145639              7.0    2015      1         130   \n",
       "\n",
       "                                              name  year_y  game_type  \\\n",
       "0                                          ZhanGuo    2014       5497   \n",
       "1  Dungeons & Dragons: Castle Ravenloft Board Game    2010       5496   \n",
       "2                                          Spyfall    2014       5498   \n",
       "3                               Rory's Story Cubes    2005  5498,5499   \n",
       "4                                         Coconuts    2013  4665,5499   \n",
       "\n",
       "                designer  ... min_time max_time  \\\n",
       "0            12293,12294  ...     60.0    120.0   \n",
       "1  2746,15913,13108,3944  ...     60.0     60.0   \n",
       "2                  78199  ...     15.0     15.0   \n",
       "3                   6409  ...     20.0     20.0   \n",
       "4                  69564  ...     20.0     20.0   \n",
       "\n",
       "                        category                            mechanic    rank  \\\n",
       "0                           1050                           2080,2040   509.0   \n",
       "1  1022,1020,1010,1046,1024,1047  2023,2072,2676,2011,2028,2819,2015   756.0   \n",
       "2       1023,1039,1079,1030,1081  2073,2047,2028,2892,2866,2814,2017   631.0   \n",
       "3                           1017                 2023,2072,2060,2027  2375.0   \n",
       "4                 1032,1089,1041                           2661,2686   919.0   \n",
       "\n",
       "   num_votes  avg_rating stddev_rating bayes_rating  complexity  \n",
       "0     2850.0     7.59899       1.25726      6.86182      3.8333  \n",
       "1     8363.0     6.97652       1.43756      6.66732      2.5111  \n",
       "2    17970.0     6.89022       1.40803      6.76383      1.2434  \n",
       "3     3145.0     6.30261       1.55489      6.00793      1.1329  \n",
       "4     3630.0     7.03525       1.28321      6.55872      1.0429  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>game_type</th>\n",
       "      <th>designer</th>\n",
       "      <th>artist</th>\n",
       "      <th>publisher</th>\n",
       "      <th>min_players</th>\n",
       "      <th>max_players</th>\n",
       "      <th>min_age</th>\n",
       "      <th>min_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>category</th>\n",
       "      <th>mechanic</th>\n",
       "      <th>rank</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>stddev_rating</th>\n",
       "      <th>bayes_rating</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Samurai</td>\n",
       "      <td>1998</td>\n",
       "      <td>5497</td>\n",
       "      <td>2</td>\n",
       "      <td>11883</td>\n",
       "      <td>17,133,267,29,7340,7335,41,2973,4617,1391,8291...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1009,1035</td>\n",
       "      <td>2080,2040,2026,2846,2004,2002</td>\n",
       "      <td>207.0</td>\n",
       "      <td>14648.0</td>\n",
       "      <td>7.45046</td>\n",
       "      <td>1.18569</td>\n",
       "      <td>7.24774</td>\n",
       "      <td>2.4885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>El Caballero</td>\n",
       "      <td>1998</td>\n",
       "      <td>5497</td>\n",
       "      <td>7,8</td>\n",
       "      <td>74</td>\n",
       "      <td>267,133,3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1020</td>\n",
       "      <td>2080,2002</td>\n",
       "      <td>2679.0</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>6.46354</td>\n",
       "      <td>1.43462</td>\n",
       "      <td>5.94897</td>\n",
       "      <td>3.1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Elfenland</td>\n",
       "      <td>1998</td>\n",
       "      <td>5499</td>\n",
       "      <td>9</td>\n",
       "      <td>74</td>\n",
       "      <td>8,267,6818,18852,3395,3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1010,1097</td>\n",
       "      <td>2041,2040,2081,2078</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>7989.0</td>\n",
       "      <td>6.71382</td>\n",
       "      <td>1.25368</td>\n",
       "      <td>6.50146</td>\n",
       "      <td>2.1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Bohnanza</td>\n",
       "      <td>1997</td>\n",
       "      <td>5499</td>\n",
       "      <td>10</td>\n",
       "      <td>28004,44242,12035,11507,11901,65041,308,12123,...</td>\n",
       "      <td>8,267,46980,7162,2378,6818,8845,155,5530,6214,...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1002,1013,1026</td>\n",
       "      <td>2040,2981,2915,2004,2008</td>\n",
       "      <td>446.0</td>\n",
       "      <td>37752.0</td>\n",
       "      <td>7.03672</td>\n",
       "      <td>1.29093</td>\n",
       "      <td>6.93425</td>\n",
       "      <td>1.6739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>Ra</td>\n",
       "      <td>1999</td>\n",
       "      <td>5497</td>\n",
       "      <td>2</td>\n",
       "      <td>20789,11883</td>\n",
       "      <td>9,34,28620,267,29,23205,2973,8291,9881,42294,3...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1050,1082</td>\n",
       "      <td>2012,2923,2928,2922,2661,2004</td>\n",
       "      <td>177.0</td>\n",
       "      <td>18975.0</td>\n",
       "      <td>7.47044</td>\n",
       "      <td>1.33831</td>\n",
       "      <td>7.31246</td>\n",
       "      <td>2.3489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bgg_id          name  year game_type designer  \\\n",
       "0       3       Samurai  1998      5497        2   \n",
       "1       9  El Caballero  1998      5497      7,8   \n",
       "2      10     Elfenland  1998      5499        9   \n",
       "3      11      Bohnanza  1997      5499       10   \n",
       "4      12            Ra  1999      5497        2   \n",
       "\n",
       "                                              artist  \\\n",
       "0                                              11883   \n",
       "1                                                 74   \n",
       "2                                                 74   \n",
       "3  28004,44242,12035,11507,11901,65041,308,12123,...   \n",
       "4                                        20789,11883   \n",
       "\n",
       "                                           publisher min_players max_players  \\\n",
       "0  17,133,267,29,7340,7335,41,2973,4617,1391,8291...           2           4   \n",
       "1                                          267,133,3           2           4   \n",
       "2                            8,267,6818,18852,3395,3           2           6   \n",
       "3  8,267,46980,7162,2378,6818,8845,155,5530,6214,...           2           7   \n",
       "4  9,34,28620,267,29,23205,2973,8291,9881,42294,3...           2           5   \n",
       "\n",
       "   min_age  min_time  max_time        category                       mechanic  \\\n",
       "0     10.0      30.0      60.0       1009,1035  2080,2040,2026,2846,2004,2002   \n",
       "1     13.0      90.0      90.0            1020                      2080,2002   \n",
       "2     10.0      60.0      60.0       1010,1097            2041,2040,2081,2078   \n",
       "3     13.0      45.0      45.0  1002,1013,1026       2040,2981,2915,2004,2008   \n",
       "4     12.0      45.0      60.0       1050,1082  2012,2923,2928,2922,2661,2004   \n",
       "\n",
       "     rank  num_votes  avg_rating  stddev_rating  bayes_rating  complexity  \n",
       "0   207.0    14648.0     7.45046        1.18569       7.24774      2.4885  \n",
       "1  2679.0     1374.0     6.46354        1.43462       5.94897      3.1824  \n",
       "2  1016.0     7989.0     6.71382        1.25368       6.50146      2.1592  \n",
       "3   446.0    37752.0     7.03672        1.29093       6.93425      1.6739  \n",
       "4   177.0    18975.0     7.47044        1.33831       7.31246      2.3489  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: {bgg_id: (), bgg_user_name: (), bgg_user_rating: (), complexity: (), game_type: (), category: (), mechanic: ()}, types: {bgg_id: tf.string, bgg_user_name: tf.string, bgg_user_rating: tf.float32, complexity: tf.float32, game_type: tf.string, category: tf.string, mechanic: tf.string}>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full model\n",
    "class BGDeepModel2(tfrs.models.Model):\n",
    "    \n",
    "    def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "        \n",
    "        # User and board game models\n",
    "        self.user_model: tf.keras.Model = user_name_model\n",
    "        self.bgg_id_model: tf.keras.Model = bgg_id_model\n",
    "        self.complexity_model: tf.keras.Model = complexity_model\n",
    "        self.game_type_model: tf.keras.Model = game_type_model\n",
    "        self.category_model: tf.keras.Model = category_model\n",
    "        self.mechanic_model: tf.keras.Model = mechanic_model\n",
    "            \n",
    "        # Model to take in user and board game embeddings and predict ratings\n",
    "        self.rating_model = Sequential([\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        \n",
    "        # Tasks\n",
    "        self.rating_task: Layer = rating_task\n",
    "        self.retrieval_task: Layer = retrieval_task\n",
    "        \n",
    "        # Loss weights\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "        \n",
    "    def call(self, features) -> tf.Tensor:\n",
    "        user_embeddings = self.user_model(features['bgg_user_name'])\n",
    "        bgg_id_embeddings = self.bgg_id_model(features['bgg_id'])\n",
    "#         complexity_embeddings = self.complexity_model(features['complexity'])\n",
    "        game_type_embeddings = self.game_type_model(features['game_type'])\n",
    "        category_embeddings = self.category_model(features['category'])\n",
    "        mechanic_embeddings = self.mechanic_model(features['mechanic'])\n",
    "        \n",
    "        return (\n",
    "            user_embeddings,\n",
    "            bgg_id_embeddings,\n",
    "#             complexity_embeddings,\n",
    "            game_type_embeddings,\n",
    "            category_embeddings,\n",
    "            mechanic_embeddings,\n",
    "            self.rating_model(tf.concat([user_embeddings, bgg_id_embeddings, #complexity_embeddings, \n",
    "                                        game_type_embeddings, category_embeddings, mechanic_embeddings], axis=1))\n",
    "        )\n",
    "    \n",
    "    def compute_loss(self, features, training=False) -> tf.Tensor:\n",
    "        ratings = features['bgg_user_rating']\n",
    "        user_embeddings, bgg_id_embeddings, game_type_embeddings, category_embeddings, mechanic_embeddings, rating_predictions = self(features)\n",
    "        #  complexity_embeddings,\n",
    "        \n",
    "        # Compute loss for each task\n",
    "        rating_loss = self.rating_task(labels=ratings, predictions=rating_predictions)\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, bgg_id_embeddings, #complexity_embeddings, \n",
    "                                             game_type_embeddings, category_embeddings, mechanic_embeddings)\n",
    "        \n",
    "        #Combine them using the loss weights\n",
    "        return (self.rating_weight * rating_loss + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and compile model\n",
    "deep_model_test = BGDeepModel2(rating_weight=1, retrieval_weight=1)\n",
    "deep_model_test.compile(optimizer=Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow_recommenders\\tasks\\retrieval.py:149 call  *\n        loss = self._loss(y_true=labels, y_pred=scores, sample_weight=sample_weight)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__  **\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, None) and (32, None, 32) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-240-2eaddc74be82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Training the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdeep_model_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcached_combined_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:806 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow_recommenders\\tasks\\retrieval.py:149 call  *\n        loss = self._loss(y_true=labels, y_pred=scores, sample_weight=sample_weight)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:149 __call__  **\n        losses = ag_call(y_true, y_pred)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    C:\\Users\\riche\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, None) and (32, None, 32) are incompatible\n"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "tf.random.set_seed(42)\n",
    "deep_model_test.fit(cached_combined_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CacheDataset shapes: ((None, 2), (None,)), types: (tf.string, tf.float32)>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_rating_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bgg_id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>game_type</th>\n",
       "      <th>designer</th>\n",
       "      <th>artist</th>\n",
       "      <th>publisher</th>\n",
       "      <th>min_players</th>\n",
       "      <th>max_players</th>\n",
       "      <th>min_age</th>\n",
       "      <th>min_time</th>\n",
       "      <th>max_time</th>\n",
       "      <th>category</th>\n",
       "      <th>mechanic</th>\n",
       "      <th>rank</th>\n",
       "      <th>num_votes</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>stddev_rating</th>\n",
       "      <th>bayes_rating</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Samurai</td>\n",
       "      <td>1998</td>\n",
       "      <td>5497</td>\n",
       "      <td>2</td>\n",
       "      <td>11883</td>\n",
       "      <td>17,133,267,29,7340,7335,41,2973,4617,1391,8291...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1009,1035</td>\n",
       "      <td>2080,2040,2026,2846,2004,2002</td>\n",
       "      <td>207.0</td>\n",
       "      <td>14648.0</td>\n",
       "      <td>7.45046</td>\n",
       "      <td>1.18569</td>\n",
       "      <td>7.24774</td>\n",
       "      <td>2.4885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>El Caballero</td>\n",
       "      <td>1998</td>\n",
       "      <td>5497</td>\n",
       "      <td>7,8</td>\n",
       "      <td>74</td>\n",
       "      <td>267,133,3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1020</td>\n",
       "      <td>2080,2002</td>\n",
       "      <td>2679.0</td>\n",
       "      <td>1374.0</td>\n",
       "      <td>6.46354</td>\n",
       "      <td>1.43462</td>\n",
       "      <td>5.94897</td>\n",
       "      <td>3.1824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Elfenland</td>\n",
       "      <td>1998</td>\n",
       "      <td>5499</td>\n",
       "      <td>9</td>\n",
       "      <td>74</td>\n",
       "      <td>8,267,6818,18852,3395,3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1010,1097</td>\n",
       "      <td>2041,2040,2081,2078</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>7989.0</td>\n",
       "      <td>6.71382</td>\n",
       "      <td>1.25368</td>\n",
       "      <td>6.50146</td>\n",
       "      <td>2.1592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>Bohnanza</td>\n",
       "      <td>1997</td>\n",
       "      <td>5499</td>\n",
       "      <td>10</td>\n",
       "      <td>28004,44242,12035,11507,11901,65041,308,12123,...</td>\n",
       "      <td>8,267,46980,7162,2378,6818,8845,155,5530,6214,...</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1002,1013,1026</td>\n",
       "      <td>2040,2981,2915,2004,2008</td>\n",
       "      <td>446.0</td>\n",
       "      <td>37752.0</td>\n",
       "      <td>7.03672</td>\n",
       "      <td>1.29093</td>\n",
       "      <td>6.93425</td>\n",
       "      <td>1.6739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>Ra</td>\n",
       "      <td>1999</td>\n",
       "      <td>5497</td>\n",
       "      <td>2</td>\n",
       "      <td>20789,11883</td>\n",
       "      <td>9,34,28620,267,29,23205,2973,8291,9881,42294,3...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1050,1082</td>\n",
       "      <td>2012,2923,2928,2922,2661,2004</td>\n",
       "      <td>177.0</td>\n",
       "      <td>18975.0</td>\n",
       "      <td>7.47044</td>\n",
       "      <td>1.33831</td>\n",
       "      <td>7.31246</td>\n",
       "      <td>2.3489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bgg_id          name  year game_type designer  \\\n",
       "0       3       Samurai  1998      5497        2   \n",
       "1       9  El Caballero  1998      5497      7,8   \n",
       "2      10     Elfenland  1998      5499        9   \n",
       "3      11      Bohnanza  1997      5499       10   \n",
       "4      12            Ra  1999      5497        2   \n",
       "\n",
       "                                              artist  \\\n",
       "0                                              11883   \n",
       "1                                                 74   \n",
       "2                                                 74   \n",
       "3  28004,44242,12035,11507,11901,65041,308,12123,...   \n",
       "4                                        20789,11883   \n",
       "\n",
       "                                           publisher min_players max_players  \\\n",
       "0  17,133,267,29,7340,7335,41,2973,4617,1391,8291...           2           4   \n",
       "1                                          267,133,3           2           4   \n",
       "2                            8,267,6818,18852,3395,3           2           6   \n",
       "3  8,267,46980,7162,2378,6818,8845,155,5530,6214,...           2           7   \n",
       "4  9,34,28620,267,29,23205,2973,8291,9881,42294,3...           2           5   \n",
       "\n",
       "   min_age  min_time  max_time        category                       mechanic  \\\n",
       "0     10.0      30.0      60.0       1009,1035  2080,2040,2026,2846,2004,2002   \n",
       "1     13.0      90.0      90.0            1020                      2080,2002   \n",
       "2     10.0      60.0      60.0       1010,1097            2041,2040,2081,2078   \n",
       "3     13.0      45.0      45.0  1002,1013,1026       2040,2981,2915,2004,2008   \n",
       "4     12.0      45.0      60.0       1050,1082  2012,2923,2928,2922,2661,2004   \n",
       "\n",
       "     rank  num_votes  avg_rating  stddev_rating  bayes_rating  complexity  \n",
       "0   207.0    14648.0     7.45046        1.18569       7.24774      2.4885  \n",
       "1  2679.0     1374.0     6.46354        1.43462       5.94897      3.1824  \n",
       "2  1016.0     7989.0     6.71382        1.25368       6.50146      2.1592  \n",
       "3   446.0    37752.0     7.03672        1.29093       6.93425      1.6739  \n",
       "4   177.0    18975.0     7.47044        1.33831       7.31246      2.3489  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4885, 3.1824])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['bgg_id'].isin(np.array([3,9])), 'complexity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42, 43])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(['42','43']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.constant('42').numpy().decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_arr_int(x):\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'3', b'4', b'4', b'5'], dtype=object)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tf.reshape(tf.constant(['3','4','4','5']), [-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2867    1.4813\n",
       "Name: complexity, dtype: float64"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['bgg_id'].isin([113294]), 'complexity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ZipDataset shapes: ((2,), ()), types: (tf.string, tf.float32)>\r\n"
     ]
    }
   ],
   "source": [
    "tf.print(rating_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Expected concatenating dimensions in the range [-1, 1), but got 1 [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-354-fc8ffc2023e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcached_rating_test\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m<=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBGDeepModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrating_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretrieval_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-350-a13cc8b80815>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mcategory_embeddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mmechanic_embeddings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             self.rating_model(tf.concat([user_embeddings, bgg_id_embeddings, complexity_embeddings, \n\u001b[0m\u001b[0;32m     47\u001b[0m                                         game_type_embeddings, category_embeddings, mechanic_embeddings], axis=1))\n\u001b[0;32m     48\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1652\u001b[0m           dtype=dtypes.int32).get_shape().assert_has_rank(0)\n\u001b[0;32m   1653\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0midentity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1654\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\u001b[0m in \u001b[0;36mconcat_v2\u001b[1;34m(values, axis, name)\u001b[0m\n\u001b[0;32m   1204\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6843\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6844\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: ConcatOp : Expected concatenating dimensions in the range [-1, 1), but got 1 [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for element in cached_rating_test:\n",
    "    if count <=10:\n",
    "        test = BGDeepModel(rating_weight=1, retrieval_weight=1)(element)\n",
    "        print(type(test))\n",
    "        print(test)\n",
    "#         print(df.loc[df['bgg_id'].isin([test]), 'complexity'].values)\n",
    "        print('----------')\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[-0.00052718  0.0358969  -0.04152752  0.03461525 -0.03203517  0.00822916\n",
      " -0.04941098  0.00573819  0.01563492  0.00611695 -0.00887588 -0.01840105\n",
      " -0.00715303  0.00944015  0.02458178  0.04004807 -0.02326866 -0.03996634\n",
      " -0.0395707  -0.04318609  0.03783612  0.03712589  0.01163585 -0.03573905\n",
      "  0.02580333 -0.04680852 -0.00112073 -0.00693706 -0.00046236  0.02940014\n",
      " -0.01455249 -0.0289237 ], shape=(32,), dtype=float32)\n",
      "----------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[-0.00154072 -0.00616825  0.0185701  -0.04434942 -0.04417172  0.04234744\n",
      " -0.00449486 -0.03945597 -0.03224485  0.03075543  0.012307   -0.01006582\n",
      "  0.00221311 -0.02897896  0.01617697 -0.04119324  0.00550137 -0.01469414\n",
      "  0.03515703 -0.01047357 -0.00142251  0.02032924 -0.02711805  0.03532335\n",
      " -0.00902539  0.02516544 -0.00799586 -0.00352271  0.00202223  0.01303159\n",
      " -0.04056958  0.01918464], shape=(32,), dtype=float32)\n",
      "----------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[-2.8049469e-02 -3.7602127e-02  2.5562894e-02 -2.2546757e-02\n",
      " -1.1089336e-02  4.6534125e-02 -2.9344333e-02 -4.9818374e-02\n",
      "  1.8029939e-02 -4.0591598e-02  1.6682748e-02  2.7972113e-02\n",
      "  3.4604240e-02 -2.0523144e-02  8.4270947e-03 -1.4137737e-03\n",
      " -1.4013778e-02  3.2932173e-02  1.4295466e-03 -4.1094899e-02\n",
      "  3.5915229e-02  1.9944500e-02 -1.6635619e-02 -2.8312063e-02\n",
      " -4.7723569e-02  4.2411480e-02  4.5656171e-02  3.4007791e-02\n",
      "  1.9507956e-02  9.2044361e-03  2.8369118e-02  1.6652048e-05], shape=(32,), dtype=float32)\n",
      "----------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[-0.0304765   0.04403986  0.01970759  0.04811207 -0.0246536   0.00797923\n",
      "  0.00570747  0.0170645  -0.04173787 -0.04105482 -0.00446893 -0.0210092\n",
      " -0.02146081  0.04573018 -0.02424628 -0.02060637  0.01818657  0.00931869\n",
      "  0.04628276 -0.03120174  0.01729161  0.01666656  0.02118767 -0.01427161\n",
      " -0.02321622  0.0331058  -0.0448056   0.0209221   0.01019073 -0.02712945\n",
      "  0.03394808  0.00774886], shape=(32,), dtype=float32)\n",
      "----------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[-0.04896222  0.01421923  0.04652214  0.02639482 -0.03032692 -0.00252055\n",
      "  0.0482995  -0.03480753 -0.03503581 -0.04803909 -0.01045359 -0.03779561\n",
      "  0.04515591  0.01886645 -0.04599592  0.02811483 -0.00125622 -0.01873237\n",
      " -0.00820144  0.01588314  0.0113825  -0.03024856 -0.04710888 -0.04753111\n",
      " -0.04896089  0.01340871 -0.0453701  -0.01980816 -0.02020317  0.04880859\n",
      " -0.0146423  -0.00653777], shape=(32,), dtype=float32)\n",
      "----------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[ 0.03702908 -0.01485674 -0.03404742 -0.04957732  0.00304693  0.03645251\n",
      "  0.00123739  0.00406411  0.01179085 -0.02196046  0.0311189  -0.04496273\n",
      " -0.04214765  0.03895411  0.00118947  0.00046944 -0.03171953 -0.00898874\n",
      " -0.04433444  0.02150059  0.03216641  0.02953403  0.04446454 -0.04690529\n",
      "  0.00721835 -0.03565316 -0.02317698 -0.00167741 -0.03201552 -0.04458857\n",
      " -0.0191463   0.0173156 ], shape=(32,), dtype=float32)\n",
      "----------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[-0.02126902  0.03939061  0.04662604 -0.01355977  0.00483024  0.04796732\n",
      "  0.02107063  0.01173419  0.00146083 -0.03446268 -0.02551646  0.04903528\n",
      "  0.02392374  0.03210944  0.01554317 -0.02545472  0.01957294 -0.03822505\n",
      " -0.00026494 -0.0340666  -0.0264584  -0.00115972 -0.03454881  0.00899402\n",
      " -0.04899959  0.04852167  0.01273397 -0.04071014 -0.03183134  0.00277074\n",
      "  0.00781941  0.00930656], shape=(32,), dtype=float32)\n",
      "----------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[-0.00119025  0.04758073  0.00266527  0.03516844 -0.03116182  0.01862487\n",
      "  0.01887393  0.03707002 -0.00327979 -0.04306264 -0.02482226  0.01888355\n",
      " -0.03467657  0.04905332  0.02160492  0.01433386  0.00374069 -0.0079525\n",
      "  0.00296431 -0.01917049 -0.03982979  0.01884114  0.03998201  0.02382148\n",
      " -0.04228293  0.00723102 -0.03757973 -0.00452935 -0.04514838 -0.04607971\n",
      "  0.0384339   0.00370921], shape=(32,), dtype=float32)\n",
      "----------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[-0.00235384 -0.03568044  0.01024783  0.02731191  0.03984665  0.01722303\n",
      " -0.04183408 -0.01131754  0.00133883 -0.04298495  0.01967521 -0.02068152\n",
      "  0.00929295 -0.04423676  0.02690027  0.03642369  0.03010929 -0.02861354\n",
      " -0.0122169  -0.00018442 -0.00662607  0.04084704  0.03579772  0.01816073\n",
      " -0.00796485 -0.00639813 -0.02052748  0.0068449  -0.00977794 -0.02797857\n",
      " -0.02396913 -0.01619925], shape=(32,), dtype=float32)\n",
      "----------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[ 0.01398263 -0.04393363  0.04280556  0.0371117   0.02114141  0.04599656\n",
      " -0.01784335  0.02249164  0.00643871 -0.00741472 -0.04884336  0.04590697\n",
      " -0.01345807 -0.02200567  0.00301582 -0.026043   -0.02703674 -0.04661569\n",
      "  0.04999915 -0.02314723 -0.0386412   0.0293612   0.04052925  0.00325989\n",
      "  0.01413709  0.00322375  0.03900286  0.01594616  0.03729602 -0.0246297\n",
      " -0.0356863   0.02405635], shape=(32,), dtype=float32)\n",
      "----------\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[ 0.04713819 -0.04183024  0.014842    0.01718767 -0.00705599 -0.04044036\n",
      "  0.02258572 -0.04327491 -0.00367036 -0.00234437  0.02046468 -0.02025095\n",
      " -0.02908434  0.00859847  0.01173677  0.0372028  -0.04020959 -0.03457274\n",
      " -0.01478007 -0.02898375 -0.0282189  -0.00949568  0.04783589  0.04617159\n",
      "  0.01286279 -0.032814    0.03382595 -0.00111907 -0.00645754  0.00631658\n",
      "  0.02467443  0.03192667], shape=(32,), dtype=float32)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for element in cached_rating_test:\n",
    "    if count <=10:\n",
    "        test = user_model(element[0][0][1])\n",
    "        print(type(test))\n",
    "        print(test)\n",
    "#         print(df.loc[df['bgg_id'].isin([test]), 'complexity'].values)\n",
    "        print('----------')\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "113294\n",
      "[1.4813]\n",
      "----------\n",
      "<class 'int'>\n",
      "146021\n",
      "[3.3192]\n",
      "----------\n",
      "<class 'int'>\n",
      "214880\n",
      "[4.042]\n",
      "----------\n",
      "<class 'int'>\n",
      "39856\n",
      "[1.2203]\n",
      "----------\n",
      "<class 'int'>\n",
      "92828\n",
      "[1.1943]\n",
      "----------\n",
      "<class 'int'>\n",
      "218603\n",
      "[2.2785]\n",
      "----------\n",
      "<class 'int'>\n",
      "246784\n",
      "[2.2429]\n",
      "----------\n",
      "<class 'int'>\n",
      "247160\n",
      "[1.]\n",
      "----------\n",
      "<class 'int'>\n",
      "24181\n",
      "[3.571]\n",
      "----------\n",
      "<class 'int'>\n",
      "35497\n",
      "[1.4795]\n",
      "----------\n",
      "<class 'int'>\n",
      "132372\n",
      "[2.0685]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Check the format of train and test datasets\n",
    "# df.loc[df['bgg_id'].isin(features[0][0].numpy().decode(\"utf-8\").astype(int)), 'complexity'].values\n",
    "count = 0\n",
    "for element in rating_test.as_numpy_iterator():\n",
    "    if count <=10:\n",
    "        test = int(element[0][0].decode(\"utf-8\"))\n",
    "        print(type(test))\n",
    "        print(test)\n",
    "        print(df.loc[df['bgg_id'].isin([test]), 'complexity'].values)\n",
    "        print('----------')\n",
    "        count += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to explore more models which are able to utilize the rich features which our datasets possess, also to give better recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-based Recommender\n",
    "\n",
    "In content-based filtering, the features of the dataframe are broken down into \"feature baskets\". These are the characteristics that represent a board game. The main idea is that if the user likes certain categories, mechanics, or types of a certain board game, then it is likely the user likes another board game that has similar characteristics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tuple(df['bgg_id'])[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "258.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
